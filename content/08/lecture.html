

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Lecture 8 – Analysis and Visualization &#8212; Machine Learning for Public Interest Technologists</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'content/08/lecture';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../../README.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.png" class="logo__image only-light" alt="Machine Learning for Public Interest Technologists - Home"/>
    <script>document.write(`<img src="../../_static/logo.png" class="logo__image only-dark" alt="Machine Learning for Public Interest Technologists - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../README.html">
                    Machine Learning (and analysis) for Public Interest Technologists
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">About This Course</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../01/lecture.html">Lecture 1 – About This Course</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01/exercise.html">Exercise 1 – Getting Setup with Colab</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01/reference.html">Exercise 1 – Reference Code</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Municipal Legislative Data</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../02/lecture.html">Lecture 2 – Municipal Legislative (Text) Data</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Counting Words</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../03/lecture.html">Lecture 3 – Counting Words</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Semantic Embeddings</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../04/lecture.html">Lecture 4 – Semantic Embeddings</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Text Classification</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../05/lecture.html">Lecture 5 – Text Classification</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/PugetSoundClinic-PIT/ml-for-pit/blob/main/content/08/lecture.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/PugetSoundClinic-PIT/ml-for-pit" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/PugetSoundClinic-PIT/ml-for-pit/issues/new?title=Issue%20on%20page%20%2Fcontent/08/lecture.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/content/08/lecture.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Lecture 8 – Analysis and Visualization</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#outline">Outline</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#coming-up-with-questions">Coming Up With Questions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#planning">Planning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#constructing-a-dataset-for-training-a-public-comment-period-start-and-end-classifier">Constructing a Dataset for Training a Public Comment Period Start and End Classifier</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-a-public-comment-period-start-and-end-classifier">Training a Public Comment Period Start and End Classifier</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-our-model-to-extract-public-comment-periods-from-meetings">Using our model to extract public comment periods from meetings</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="lecture-8-analysis-and-visualization">
<h1>Lecture 8 – Analysis and Visualization<a class="headerlink" href="#lecture-8-analysis-and-visualization" title="Permalink to this heading">#</a></h1>
<section id="outline">
<h2>Outline<a class="headerlink" href="#outline" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>We have learned how many different tools work, how to apply them, and how to train and build some of our own models.</p></li>
<li><p>however, we have not yet taken the step of applying these tools together in a meaningful way.</p></li>
<li><p>in this chapter we are going to do just that</p></li>
<li><p>we will use the tools we have learned to answer a question by analyzing a dataset and visualizing and reporting our results</p></li>
</ul>
</section>
<section id="coming-up-with-questions">
<h2>Coming Up With Questions<a class="headerlink" href="#coming-up-with-questions" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>there are a lot of questions we can ask about this data. but generally a good place to start is by asking something simple that may reveal a larger pattern for further investigation</p></li>
<li><p>for example, lets try to answer the question “how are public comment’s typically structured in city council meetings?”</p></li>
</ul>
</section>
<section id="planning">
<h2>Planning<a class="headerlink" href="#planning" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>our first step in this process is to break down how we can answer our question</p></li>
<li><p>within each meeting, we will want to identify the sentences / portions which are public comments – when you are working on identification problems, <strong>classification</strong> is always a good place to start</p></li>
<li><p>we will also want to look into the structure. a few examples of public comments might be (note, the names and organizations are made up, but the sentence structure comes directly from meetings of the Seattle City Council):</p>
<ul>
<li><p>Good afternoon, Councilmembers. My name is Lisa and I’m speaking for Parents for Police today. And we, I’d like to support, here to support the appointment of Bill as Executive Director of the CPC. …</p></li>
<li><p>Hello, I’m Bryce Chin, Chair of Justice Washington and a District 7 constituent. I am speaking in opposition to the SPOG MOU. …</p></li>
<li><p>Hi, council members. My name is Tim Brown and I live on Capitol Hill and run a small business in Soto. I’m calling today to urge you to vote no on the SPOG memo of understanding. …</p></li>
</ul>
</li>
<li><p>we can see that there are a few different structures here. some people introduce themselves, some people introduce their organization, some people introduce their district, they usually say what they are speaking about, and then they say what they want the council to do</p></li>
<li><p>To start, lets try to breakdown comments by:</p>
<ul>
<li><p>“self-introduction” - the speaker introduces themselves</p></li>
<li><p>“org-introduction” - the speaker can optionally introduce themselves but additionally introduces an organization</p></li>
<li><p>“other” - the speaker does not introduce themselves or an organization</p></li>
</ul>
</li>
<li><p>this is a complex task, and one we can likely train yet another classification model for but we might want to use something to help us annotate data</p></li>
<li><p>before we do any of this, we will probably want to work with a small dataset before scaling up to the entire corpus</p></li>
<li><p>lets start by trying to identify the start and end of the public comment / public hearing sections of the meeting</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">cdp_data</span> <span class="kn">import</span> <span class="n">CDPInstances</span><span class="p">,</span> <span class="n">datasets</span>

<span class="n">sessions</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">get_session_dataset</span><span class="p">(</span>
    <span class="n">CDPInstances</span><span class="o">.</span><span class="n">Seattle</span><span class="p">,</span>
    <span class="n">start_datetime</span><span class="o">=</span><span class="s2">&quot;2021-01-01&quot;</span><span class="p">,</span>
    <span class="n">end_datetime</span><span class="o">=</span><span class="s2">&quot;2022-01-01&quot;</span><span class="p">,</span>
    <span class="n">store_transcript</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">raise_on_error</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">sessions</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "459357b924d34d77853392a34195f9c8"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "a099a864d75b420ab88bde11c3565ffc"}</script><div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>session_datetime</th>
      <th>session_index</th>
      <th>session_content_hash</th>
      <th>video_uri</th>
      <th>video_start_time</th>
      <th>video_end_time</th>
      <th>caption_uri</th>
      <th>external_source_id</th>
      <th>id</th>
      <th>key</th>
      <th>event</th>
      <th>transcript</th>
      <th>transcript_path</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2021-01-04 17:30:00+00:00</td>
      <td>0</td>
      <td>afb06065232167ccc35ad4cc7bb24c46a67357846c6acd...</td>
      <td>https://video.seattle.gov/media/council/brief_...</td>
      <td>None</td>
      <td>None</td>
      <td>https://www.seattlechannel.org/documents/seatt...</td>
      <td>None</td>
      <td>de9d821a3aba</td>
      <td>session/de9d821a3aba</td>
      <td>&lt;cdp_backend.database.models.Event object at 0...</td>
      <td>&lt;cdp_backend.database.models.Transcript object...</td>
      <td>/home/runner/work/ml-for-pit/ml-for-pit/conten...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2021-01-04 22:00:00+00:00</td>
      <td>0</td>
      <td>81a736cb5605f776712765dd770df7a28f554987c893ea...</td>
      <td>https://video.seattle.gov/media/council/counci...</td>
      <td>None</td>
      <td>None</td>
      <td>https://www.seattlechannel.org/documents/seatt...</td>
      <td>None</td>
      <td>f1434b7a9fa2</td>
      <td>session/f1434b7a9fa2</td>
      <td>&lt;cdp_backend.database.models.Event object at 0...</td>
      <td>&lt;cdp_backend.database.models.Transcript object...</td>
      <td>/home/runner/work/ml-for-pit/ml-for-pit/conten...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2021-01-11 17:30:00+00:00</td>
      <td>0</td>
      <td>8265168b36b383e19509244766c0d4e789230ee839371b...</td>
      <td>https://video.seattle.gov/media/council/brief_...</td>
      <td>None</td>
      <td>None</td>
      <td>https://www.seattlechannel.org/documents/seatt...</td>
      <td>None</td>
      <td>fe7c8aa0dd58</td>
      <td>session/fe7c8aa0dd58</td>
      <td>&lt;cdp_backend.database.models.Event object at 0...</td>
      <td>&lt;cdp_backend.database.models.Transcript object...</td>
      <td>/home/runner/work/ml-for-pit/ml-for-pit/conten...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2021-01-11 22:00:00+00:00</td>
      <td>0</td>
      <td>386d37689ea482446c8837f1a950c66af9d0bbf7f04ba0...</td>
      <td>https://video.seattle.gov/media/council/counci...</td>
      <td>None</td>
      <td>None</td>
      <td>https://www.seattlechannel.org/documents/seatt...</td>
      <td>None</td>
      <td>2b30cc0f5847</td>
      <td>session/2b30cc0f5847</td>
      <td>&lt;cdp_backend.database.models.Event object at 0...</td>
      <td>&lt;cdp_backend.database.models.Transcript object...</td>
      <td>/home/runner/work/ml-for-pit/ml-for-pit/conten...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2021-01-12 17:30:00+00:00</td>
      <td>0</td>
      <td>91118e8a210e92600a869df3e4e4b7c27b2785d025c2f0...</td>
      <td>https://video.seattle.gov/media/council/safe_0...</td>
      <td>None</td>
      <td>None</td>
      <td>https://www.seattlechannel.org/documents/seatt...</td>
      <td>None</td>
      <td>eff5db85156a</td>
      <td>session/eff5db85156a</td>
      <td>&lt;cdp_backend.database.models.Event object at 0...</td>
      <td>&lt;cdp_backend.database.models.Transcript object...</td>
      <td>/home/runner/work/ml-for-pit/ml-for-pit/conten...</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>221</th>
      <td>2021-12-10 17:30:00+00:00</td>
      <td>0</td>
      <td>30fa17ba9b2eab53bf435b47a16dc97f6130dc1ac31dca...</td>
      <td>https://video.seattle.gov/media/council/econ_1...</td>
      <td>None</td>
      <td>None</td>
      <td>https://www.seattlechannel.org/documents/seatt...</td>
      <td>None</td>
      <td>5930000b2d24</td>
      <td>session/5930000b2d24</td>
      <td>&lt;cdp_backend.database.models.Event object at 0...</td>
      <td>&lt;cdp_backend.database.models.Transcript object...</td>
      <td>/home/runner/work/ml-for-pit/ml-for-pit/conten...</td>
    </tr>
    <tr>
      <th>222</th>
      <td>2021-12-13 17:30:00+00:00</td>
      <td>0</td>
      <td>0c190b87881c4d1c598ec67eb267129170ee2e773550df...</td>
      <td>https://video.seattle.gov/media/council/brief_...</td>
      <td>None</td>
      <td>None</td>
      <td>https://www.seattlechannel.org/documents/seatt...</td>
      <td>None</td>
      <td>62504aeb2c9e</td>
      <td>session/62504aeb2c9e</td>
      <td>&lt;cdp_backend.database.models.Event object at 0...</td>
      <td>&lt;cdp_backend.database.models.Transcript object...</td>
      <td>/home/runner/work/ml-for-pit/ml-for-pit/conten...</td>
    </tr>
    <tr>
      <th>223</th>
      <td>2021-12-13 22:00:00+00:00</td>
      <td>0</td>
      <td>ce27b141953c0e4e281ff6d99bb98fae719b0447a8690a...</td>
      <td>https://video.seattle.gov/media/council/counci...</td>
      <td>None</td>
      <td>None</td>
      <td>https://www.seattlechannel.org/documents/seatt...</td>
      <td>None</td>
      <td>726ec414e79f</td>
      <td>session/726ec414e79f</td>
      <td>&lt;cdp_backend.database.models.Event object at 0...</td>
      <td>&lt;cdp_backend.database.models.Transcript object...</td>
      <td>/home/runner/work/ml-for-pit/ml-for-pit/conten...</td>
    </tr>
    <tr>
      <th>224</th>
      <td>2021-12-14 17:30:00+00:00</td>
      <td>0</td>
      <td>1d5d9034b132cdc8702ce7399729a9a01526639cc8e4fb...</td>
      <td>https://video.seattle.gov/media/council/safe_1...</td>
      <td>None</td>
      <td>None</td>
      <td>https://www.seattlechannel.org/documents/seatt...</td>
      <td>None</td>
      <td>42c7d47dd1b9</td>
      <td>session/42c7d47dd1b9</td>
      <td>&lt;cdp_backend.database.models.Event object at 0...</td>
      <td>&lt;cdp_backend.database.models.Transcript object...</td>
      <td>/home/runner/work/ml-for-pit/ml-for-pit/conten...</td>
    </tr>
    <tr>
      <th>225</th>
      <td>2021-12-15 17:30:00+00:00</td>
      <td>0</td>
      <td>4c0f613004c3f1413ad8135f3adf3e525956a1543c48e0...</td>
      <td>https://video.seattle.gov/media/council/tran_1...</td>
      <td>None</td>
      <td>None</td>
      <td>https://www.seattlechannel.org/documents/seatt...</td>
      <td>None</td>
      <td>b7286476b38f</td>
      <td>session/b7286476b38f</td>
      <td>&lt;cdp_backend.database.models.Event object at 0...</td>
      <td>&lt;cdp_backend.database.models.Transcript object...</td>
      <td>/home/runner/work/ml-for-pit/ml-for-pit/conten...</td>
    </tr>
  </tbody>
</table>
<p>226 rows × 13 columns</p>
</div></div></div>
</div>
</section>
<section id="constructing-a-dataset-for-training-a-public-comment-period-start-and-end-classifier">
<h2>Constructing a Dataset for Training a Public Comment Period Start and End Classifier<a class="headerlink" href="#constructing-a-dataset-for-training-a-public-comment-period-start-and-end-classifier" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>the first thing we will want to do is to identify the start and end of the public comment sections</p></li>
<li><p>to do so, lets construct a dataset for annotation</p></li>
<li><p>we are going to try and help ourselves as much as possible with the annotation by using a few tools</p></li>
<li><p>first, we will iterate over a sample of the meetings and read the transcript</p></li>
<li><p>we will then embed each of the sentences within each transcript and calculate the cosine similarity between the current sentence and “ideal” sentences for the start and end of a public comment section.</p></li>
<li><p>these usually look like “the public comment period is now open” and “the public comment period is now closed”</p></li>
<li><p>for each meeting, we we will then take the top three most similar sentences for of the “ideal” sentences and build a dataset for annotation</p></li>
<li><p>further, we will use something call “negative sampling” to help gather up examples that are by estimate, not likely to be related to the start or end of a public comment section</p>
<ul>
<li><p>more reading on “negative sampling” can be found here: <a class="reference external" href="http://deepdive.stanford.edu/generating_negative_examples">http://deepdive.stanford.edu/generating_negative_examples</a></p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">cdp_backend.pipeline.transcript_model</span> <span class="kn">import</span> <span class="n">Transcript</span>
<span class="kn">from</span> <span class="nn">sentence_transformers</span> <span class="kn">import</span> <span class="n">SentenceTransformer</span>
<span class="kn">from</span> <span class="nn">sentence_transformers.util</span> <span class="kn">import</span> <span class="n">cos_sim</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># Set seed</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Init the model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">SentenceTransformer</span><span class="p">(</span><span class="s2">&quot;all-MiniLM-L6-v2&quot;</span><span class="p">)</span>

<span class="c1"># Embed the &quot;ideal&quot; open and close statements</span>
<span class="n">pc_open</span> <span class="o">=</span> <span class="s2">&quot;The public comment period is now open&quot;</span>
<span class="n">pc_closed</span> <span class="o">=</span> <span class="s2">&quot;The public comment period is now closed&quot;</span>
<span class="n">pc_open_embed</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">pc_open</span><span class="p">)</span>
<span class="n">pc_closed_embed</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">pc_closed</span><span class="p">)</span>

<span class="c1"># Sampled sessions</span>
<span class="n">samples_sessions</span> <span class="o">=</span> <span class="n">sessions</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>

<span class="c1"># For each session, open the transcript,</span>
<span class="c1"># get the top three most similar sentences to the open and close statements</span>
<span class="n">n_random_sentences</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">statements_for_annotation</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">session</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span>
    <span class="n">samples_sessions</span><span class="o">.</span><span class="n">iterrows</span><span class="p">(),</span>
    <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">samples_sessions</span><span class="p">),</span>
    <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Sessions&quot;</span><span class="p">,</span>
<span class="p">):</span>
    <span class="c1"># Read transcript</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">session</span><span class="o">.</span><span class="n">transcript_path</span><span class="p">)</span> <span class="k">as</span> <span class="n">open_f</span><span class="p">:</span>
        <span class="n">transcript</span> <span class="o">=</span> <span class="n">Transcript</span><span class="o">.</span><span class="n">from_json</span><span class="p">(</span><span class="n">open_f</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>

    <span class="c1"># Get the top three most similar sentences to the open statement</span>
    <span class="n">open_similarities</span> <span class="o">=</span> <span class="n">cos_sim</span><span class="p">(</span>
        <span class="n">pc_open_embed</span><span class="p">,</span>
        <span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">([</span><span class="n">s</span><span class="o">.</span><span class="n">text</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">transcript</span><span class="o">.</span><span class="n">sentences</span><span class="p">]),</span>
    <span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
    <span class="n">open_similarities</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">open_similarities</span><span class="p">)</span>
    <span class="n">open_similarities</span> <span class="o">=</span> <span class="n">open_similarities</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">open_similarities</span> <span class="o">=</span> <span class="n">open_similarities</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span>

    <span class="c1"># Get sentences associated with top three</span>
    <span class="n">open_sentences</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">transcript</span><span class="o">.</span><span class="n">sentences</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">open_similarities</span><span class="o">.</span><span class="n">index</span>
    <span class="p">]</span>
    <span class="c1"># Add these to the dataframe</span>
    <span class="n">open_sentences_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="s2">&quot;infra&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">CDPInstances</span><span class="o">.</span><span class="n">Seattle</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">open_sentences</span><span class="p">),</span>
            <span class="s2">&quot;session_id&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">session</span><span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">]]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">open_sentences</span><span class="p">),</span>
            <span class="s2">&quot;sentence&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">s</span><span class="o">.</span><span class="n">text</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">open_sentences</span><span class="p">],</span>
            <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">open_sentences</span><span class="p">),</span>
        <span class="p">}</span>
    <span class="p">)</span>

    <span class="c1"># Get the top three most similar sentences to the close statement</span>
    <span class="n">close_similarities</span> <span class="o">=</span> <span class="n">cos_sim</span><span class="p">(</span>
        <span class="n">pc_closed_embed</span><span class="p">,</span>
        <span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">([</span><span class="n">s</span><span class="o">.</span><span class="n">text</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">transcript</span><span class="o">.</span><span class="n">sentences</span><span class="p">]),</span>
    <span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
    <span class="n">close_similarities</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">close_similarities</span><span class="p">)</span>
    <span class="n">close_similarities</span> <span class="o">=</span> <span class="n">close_similarities</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">close_similarities</span> <span class="o">=</span> <span class="n">close_similarities</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span>
    
    <span class="c1"># Get sentences associated with top three</span>
    <span class="n">close_sentences</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">transcript</span><span class="o">.</span><span class="n">sentences</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">close_similarities</span><span class="o">.</span><span class="n">index</span>
    <span class="p">]</span>
    <span class="c1"># Add these to the dataframe</span>
    <span class="n">close_sentences_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="s2">&quot;infra&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">CDPInstances</span><span class="o">.</span><span class="n">Seattle</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">close_sentences</span><span class="p">),</span>
            <span class="s2">&quot;session_id&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">session</span><span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">]]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">close_sentences</span><span class="p">),</span>
            <span class="s2">&quot;sentence&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">s</span><span class="o">.</span><span class="n">text</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">close_sentences</span><span class="p">],</span>
            <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">close_sentences</span><span class="p">),</span>
        <span class="p">}</span>
    <span class="p">)</span>

    <span class="c1"># Also add n_random_sentences random sentences from the transcript pre-labeled as False</span>
    <span class="c1"># This is called negative sampling</span>
    <span class="c1"># The main idea is that because the transcripts have so much more data than just the open and close statements</span>
    <span class="c1"># we can randomly select some sentences and assume they are not open or close statements</span>
    <span class="c1"># This is a good way to get a lot of negative examples</span>
    <span class="n">random_negative_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span>
        <span class="n">transcript</span><span class="o">.</span><span class="n">sentences</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_random_sentences</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">)</span>
    <span class="n">random_negative_samples_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="s2">&quot;infra&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">CDPInstances</span><span class="o">.</span><span class="n">Seattle</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">random_negative_samples</span><span class="p">),</span>
            <span class="s2">&quot;session_id&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">session</span><span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">]]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">random_negative_samples</span><span class="p">),</span>
            <span class="s2">&quot;sentence&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">s</span><span class="o">.</span><span class="n">text</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">random_negative_samples</span><span class="p">],</span>
            <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;other&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">random_negative_samples</span><span class="p">),</span>
        <span class="p">}</span>
    <span class="p">)</span>

    <span class="c1"># Concatenate the open and close dataframes</span>
    <span class="n">statements_for_annotation</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
        <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">open_sentences_df</span><span class="p">,</span> <span class="n">close_sentences_df</span><span class="p">,</span> <span class="n">random_negative_samples_df</span><span class="p">])</span>
    <span class="p">)</span>

<span class="c1"># Concatenate all the dataframes in the statements_for_annotation list</span>
<span class="n">statements_for_annotation</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">statements_for_annotation</span><span class="p">)</span>

<span class="c1"># It&#39;s likely that some of the sentences are duplicates</span>
<span class="c1"># We can remove these by dropping duplicates</span>
<span class="n">statements_for_annotation</span> <span class="o">=</span> <span class="n">statements_for_annotation</span><span class="o">.</span><span class="n">drop_duplicates</span><span class="p">(</span>
    <span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;session_id&quot;</span><span class="p">,</span> <span class="s2">&quot;sentence&quot;</span><span class="p">],</span>
<span class="p">)</span>

<span class="n">statements_for_annotation</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "029ece14b0394f34800f0686ac05102f"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "13a976fbe9c24de196d031a3b84513d4"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "645274683c8e46ef94f1f40ec53a3429"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "7925049eba1d4e9288a9a552a5ab2dde"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "2994dbb853fa43d880f682b83840fdcd"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "808b4b5dd26f4c069663f94536a5023f"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "be391fbee5524d3f9d2bc6b5782f1f80"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "0daf911608be4babbe384ea75a8e1379"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "9754075f724c4c80bdb770bca62cc418"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "145059cd2fea4060aed724c3b4fd59f1"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "7b5ee315dbbd489c8e41bbb4a3a43c1f"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "6d78a6e15f4148818dd60a8ecc2a486a"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "e43433f6e7194e91a66b1def2ad6fc6b"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "c9f89e8060614a21a50c9ec6cc8f01c0"}</script><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sessions:   0%|          | 0/100 [00:00&lt;?, ?it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sessions:   1%|          | 1/100 [00:08&lt;13:17,  8.06s/it]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sessions:   1%|          | 1/100 [00:24&lt;40:22, 24.47s/it]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">KeyboardInterrupt</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">line</span> <span class="mi">62</span>
<span class="g g-Whitespace">     </span><span class="mi">50</span> <span class="n">open_sentences_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
<span class="g g-Whitespace">     </span><span class="mi">51</span>     <span class="p">{</span>
<span class="g g-Whitespace">     </span><span class="mi">52</span>         <span class="s2">&quot;infra&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">CDPInstances</span><span class="o">.</span><span class="n">Seattle</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">open_sentences</span><span class="p">),</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">56</span>     <span class="p">}</span>
<span class="g g-Whitespace">     </span><span class="mi">57</span> <span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">59</span> <span class="c1"># Get the top three most similar sentences to the close statement</span>
<span class="g g-Whitespace">     </span><span class="mi">60</span> <span class="n">close_similarities</span> <span class="o">=</span> <span class="n">cos_sim</span><span class="p">(</span>
<span class="g g-Whitespace">     </span><span class="mi">61</span>     <span class="n">pc_closed_embed</span><span class="p">,</span>
<span class="ne">---&gt; </span><span class="mi">62</span>     <span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">([</span><span class="n">s</span><span class="o">.</span><span class="n">text</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">transcript</span><span class="o">.</span><span class="n">sentences</span><span class="p">]),</span>
<span class="g g-Whitespace">     </span><span class="mi">63</span> <span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
<span class="g g-Whitespace">     </span><span class="mi">64</span> <span class="n">close_similarities</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">close_similarities</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">65</span> <span class="n">close_similarities</span> <span class="o">=</span> <span class="n">close_similarities</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="nn">File ~/.local/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:165,</span> in <span class="ni">SentenceTransformer.encode</span><span class="nt">(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)</span>
<span class="g g-Whitespace">    </span><span class="mi">162</span> <span class="n">features</span> <span class="o">=</span> <span class="n">batch_to_device</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">164</span> <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="ne">--&gt; </span><span class="mi">165</span>     <span class="n">out_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">167</span>     <span class="k">if</span> <span class="n">output_value</span> <span class="o">==</span> <span class="s1">&#39;token_embeddings&#39;</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">168</span>         <span class="n">embeddings</span> <span class="o">=</span> <span class="p">[]</span>

<span class="nn">File ~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:215,</span> in <span class="ni">Sequential.forward</span><span class="nt">(self, input)</span>
<span class="g g-Whitespace">    </span><span class="mi">213</span> <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">214</span>     <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">215</span>         <span class="nb">input</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">216</span>     <span class="k">return</span> <span class="nb">input</span>

<span class="nn">File ~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518,</span> in <span class="ni">Module._wrapped_call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1516</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compiled_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>  <span class="c1"># type: ignore[misc]</span>
<span class="g g-Whitespace">   </span><span class="mi">1517</span> <span class="k">else</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1518</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nn">File ~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527,</span> in <span class="ni">Module._call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1522</span> <span class="c1"># If we don&#39;t have any hooks, we want to skip the rest of the logic in</span>
<span class="g g-Whitespace">   </span><span class="mi">1523</span> <span class="c1"># this function, and just call forward.</span>
<span class="g g-Whitespace">   </span><span class="mi">1524</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_pre_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1525</span>         <span class="ow">or</span> <span class="n">_global_backward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1526</span>         <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1527</span>     <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1529</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1530</span>     <span class="n">result</span> <span class="o">=</span> <span class="kc">None</span>

<span class="nn">File ~/.local/lib/python3.10/site-packages/sentence_transformers/models/Transformer.py:66,</span> in <span class="ni">Transformer.forward</span><span class="nt">(self, features)</span>
<span class="g g-Whitespace">     </span><span class="mi">63</span> <span class="k">if</span> <span class="s1">&#39;token_type_ids&#39;</span> <span class="ow">in</span> <span class="n">features</span><span class="p">:</span>
<span class="g g-Whitespace">     </span><span class="mi">64</span>     <span class="n">trans_features</span><span class="p">[</span><span class="s1">&#39;token_type_ids&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="s1">&#39;token_type_ids&#39;</span><span class="p">]</span>
<span class="ne">---&gt; </span><span class="mi">66</span> <span class="n">output_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">auto_model</span><span class="p">(</span><span class="o">**</span><span class="n">trans_features</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">67</span> <span class="n">output_tokens</span> <span class="o">=</span> <span class="n">output_states</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="g g-Whitespace">     </span><span class="mi">69</span> <span class="n">features</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;token_embeddings&#39;</span><span class="p">:</span> <span class="n">output_tokens</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">:</span> <span class="n">features</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">]})</span>

<span class="nn">File ~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518,</span> in <span class="ni">Module._wrapped_call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1516</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compiled_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>  <span class="c1"># type: ignore[misc]</span>
<span class="g g-Whitespace">   </span><span class="mi">1517</span> <span class="k">else</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1518</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nn">File ~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527,</span> in <span class="ni">Module._call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1522</span> <span class="c1"># If we don&#39;t have any hooks, we want to skip the rest of the logic in</span>
<span class="g g-Whitespace">   </span><span class="mi">1523</span> <span class="c1"># this function, and just call forward.</span>
<span class="g g-Whitespace">   </span><span class="mi">1524</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_pre_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1525</span>         <span class="ow">or</span> <span class="n">_global_backward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1526</span>         <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1527</span>     <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1529</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1530</span>     <span class="n">result</span> <span class="o">=</span> <span class="kc">None</span>

<span class="nn">File ~/.local/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1013,</span> in <span class="ni">BertModel.forward</span><span class="nt">(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)</span>
<span class="g g-Whitespace">   </span><span class="mi">1004</span> <span class="n">head_mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_head_mask</span><span class="p">(</span><span class="n">head_mask</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">num_hidden_layers</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1006</span> <span class="n">embedding_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1007</span>     <span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1008</span>     <span class="n">position_ids</span><span class="o">=</span><span class="n">position_ids</span><span class="p">,</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1011</span>     <span class="n">past_key_values_length</span><span class="o">=</span><span class="n">past_key_values_length</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1012</span> <span class="p">)</span>
<span class="ne">-&gt; </span><span class="mi">1013</span> <span class="n">encoder_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1014</span>     <span class="n">embedding_output</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1015</span>     <span class="n">attention_mask</span><span class="o">=</span><span class="n">extended_attention_mask</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1016</span>     <span class="n">head_mask</span><span class="o">=</span><span class="n">head_mask</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1017</span>     <span class="n">encoder_hidden_states</span><span class="o">=</span><span class="n">encoder_hidden_states</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1018</span>     <span class="n">encoder_attention_mask</span><span class="o">=</span><span class="n">encoder_extended_attention_mask</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1019</span>     <span class="n">past_key_values</span><span class="o">=</span><span class="n">past_key_values</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1020</span>     <span class="n">use_cache</span><span class="o">=</span><span class="n">use_cache</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1021</span>     <span class="n">output_attentions</span><span class="o">=</span><span class="n">output_attentions</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1022</span>     <span class="n">output_hidden_states</span><span class="o">=</span><span class="n">output_hidden_states</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1023</span>     <span class="n">return_dict</span><span class="o">=</span><span class="n">return_dict</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1024</span> <span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1025</span> <span class="n">sequence_output</span> <span class="o">=</span> <span class="n">encoder_outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="g g-Whitespace">   </span><span class="mi">1026</span> <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pooler</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pooler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>

<span class="nn">File ~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518,</span> in <span class="ni">Module._wrapped_call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1516</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compiled_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>  <span class="c1"># type: ignore[misc]</span>
<span class="g g-Whitespace">   </span><span class="mi">1517</span> <span class="k">else</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1518</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nn">File ~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527,</span> in <span class="ni">Module._call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1522</span> <span class="c1"># If we don&#39;t have any hooks, we want to skip the rest of the logic in</span>
<span class="g g-Whitespace">   </span><span class="mi">1523</span> <span class="c1"># this function, and just call forward.</span>
<span class="g g-Whitespace">   </span><span class="mi">1524</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_pre_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1525</span>         <span class="ow">or</span> <span class="n">_global_backward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1526</span>         <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1527</span>     <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1529</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1530</span>     <span class="n">result</span> <span class="o">=</span> <span class="kc">None</span>

<span class="nn">File ~/.local/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:607,</span> in <span class="ni">BertEncoder.forward</span><span class="nt">(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)</span>
<span class="g g-Whitespace">    </span><span class="mi">596</span>     <span class="n">layer_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_gradient_checkpointing_func</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">597</span>         <span class="n">layer_module</span><span class="o">.</span><span class="fm">__call__</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">598</span>         <span class="n">hidden_states</span><span class="p">,</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">604</span>         <span class="n">output_attentions</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">605</span>     <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">606</span> <span class="k">else</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">607</span>     <span class="n">layer_outputs</span> <span class="o">=</span> <span class="n">layer_module</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">608</span>         <span class="n">hidden_states</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">609</span>         <span class="n">attention_mask</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">610</span>         <span class="n">layer_head_mask</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">611</span>         <span class="n">encoder_hidden_states</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">612</span>         <span class="n">encoder_attention_mask</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">613</span>         <span class="n">past_key_value</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">614</span>         <span class="n">output_attentions</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">615</span>     <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">617</span> <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">layer_outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="g g-Whitespace">    </span><span class="mi">618</span> <span class="k">if</span> <span class="n">use_cache</span><span class="p">:</span>

<span class="nn">File ~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518,</span> in <span class="ni">Module._wrapped_call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1516</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compiled_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>  <span class="c1"># type: ignore[misc]</span>
<span class="g g-Whitespace">   </span><span class="mi">1517</span> <span class="k">else</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1518</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nn">File ~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527,</span> in <span class="ni">Module._call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1522</span> <span class="c1"># If we don&#39;t have any hooks, we want to skip the rest of the logic in</span>
<span class="g g-Whitespace">   </span><span class="mi">1523</span> <span class="c1"># this function, and just call forward.</span>
<span class="g g-Whitespace">   </span><span class="mi">1524</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_pre_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1525</span>         <span class="ow">or</span> <span class="n">_global_backward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1526</span>         <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1527</span>     <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1529</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1530</span>     <span class="n">result</span> <span class="o">=</span> <span class="kc">None</span>

<span class="nn">File ~/.local/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:497,</span> in <span class="ni">BertLayer.forward</span><span class="nt">(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)</span>
<span class="g g-Whitespace">    </span><span class="mi">485</span> <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">486</span>     <span class="bp">self</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">487</span>     <span class="n">hidden_states</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">494</span> <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="g g-Whitespace">    </span><span class="mi">495</span>     <span class="c1"># decoder uni-directional self-attention cached key/values tuple is at positions 1,2</span>
<span class="g g-Whitespace">    </span><span class="mi">496</span>     <span class="n">self_attn_past_key_value</span> <span class="o">=</span> <span class="n">past_key_value</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span> <span class="k">if</span> <span class="n">past_key_value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
<span class="ne">--&gt; </span><span class="mi">497</span>     <span class="n">self_attention_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">498</span>         <span class="n">hidden_states</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">499</span>         <span class="n">attention_mask</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">500</span>         <span class="n">head_mask</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">501</span>         <span class="n">output_attentions</span><span class="o">=</span><span class="n">output_attentions</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">502</span>         <span class="n">past_key_value</span><span class="o">=</span><span class="n">self_attn_past_key_value</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">503</span>     <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">504</span>     <span class="n">attention_output</span> <span class="o">=</span> <span class="n">self_attention_outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="g g-Whitespace">    </span><span class="mi">506</span>     <span class="c1"># if decoder, the last output is tuple of self-attn cache</span>

<span class="nn">File ~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518,</span> in <span class="ni">Module._wrapped_call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1516</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compiled_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>  <span class="c1"># type: ignore[misc]</span>
<span class="g g-Whitespace">   </span><span class="mi">1517</span> <span class="k">else</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1518</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nn">File ~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527,</span> in <span class="ni">Module._call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1522</span> <span class="c1"># If we don&#39;t have any hooks, we want to skip the rest of the logic in</span>
<span class="g g-Whitespace">   </span><span class="mi">1523</span> <span class="c1"># this function, and just call forward.</span>
<span class="g g-Whitespace">   </span><span class="mi">1524</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_pre_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1525</span>         <span class="ow">or</span> <span class="n">_global_backward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1526</span>         <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1527</span>     <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1529</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1530</span>     <span class="n">result</span> <span class="o">=</span> <span class="kc">None</span>

<span class="nn">File ~/.local/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:427,</span> in <span class="ni">BertAttention.forward</span><span class="nt">(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)</span>
<span class="g g-Whitespace">    </span><span class="mi">417</span> <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">418</span>     <span class="bp">self</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">419</span>     <span class="n">hidden_states</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">425</span>     <span class="n">output_attentions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">426</span> <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="ne">--&gt; </span><span class="mi">427</span>     <span class="n">self_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">self</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">428</span>         <span class="n">hidden_states</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">429</span>         <span class="n">attention_mask</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">430</span>         <span class="n">head_mask</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">431</span>         <span class="n">encoder_hidden_states</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">432</span>         <span class="n">encoder_attention_mask</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">433</span>         <span class="n">past_key_value</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">434</span>         <span class="n">output_attentions</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">435</span>     <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">436</span>     <span class="n">attention_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="n">self_outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">hidden_states</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">437</span>     <span class="n">outputs</span> <span class="o">=</span> <span class="p">(</span><span class="n">attention_output</span><span class="p">,)</span> <span class="o">+</span> <span class="n">self_outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>  <span class="c1"># add attentions if we output them</span>

<span class="nn">File ~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518,</span> in <span class="ni">Module._wrapped_call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1516</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compiled_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>  <span class="c1"># type: ignore[misc]</span>
<span class="g g-Whitespace">   </span><span class="mi">1517</span> <span class="k">else</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1518</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nn">File ~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527,</span> in <span class="ni">Module._call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1522</span> <span class="c1"># If we don&#39;t have any hooks, we want to skip the rest of the logic in</span>
<span class="g g-Whitespace">   </span><span class="mi">1523</span> <span class="c1"># this function, and just call forward.</span>
<span class="g g-Whitespace">   </span><span class="mi">1524</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_pre_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1525</span>         <span class="ow">or</span> <span class="n">_global_backward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1526</span>         <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1527</span>     <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1529</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1530</span>     <span class="n">result</span> <span class="o">=</span> <span class="kc">None</span>

<span class="nn">File ~/.local/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:308,</span> in <span class="ni">BertSelfAttention.forward</span><span class="nt">(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)</span>
<span class="g g-Whitespace">    </span><span class="mi">306</span>     <span class="n">value_layer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">past_key_value</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">value_layer</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">307</span> <span class="k">else</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">308</span>     <span class="n">key_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_for_scores</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">key</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">))</span>
<span class="g g-Whitespace">    </span><span class="mi">309</span>     <span class="n">value_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_for_scores</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">value</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">))</span>
<span class="g g-Whitespace">    </span><span class="mi">311</span> <span class="n">query_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_for_scores</span><span class="p">(</span><span class="n">mixed_query_layer</span><span class="p">)</span>

<span class="nn">File ~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518,</span> in <span class="ni">Module._wrapped_call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1516</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compiled_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>  <span class="c1"># type: ignore[misc]</span>
<span class="g g-Whitespace">   </span><span class="mi">1517</span> <span class="k">else</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1518</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nn">File ~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527,</span> in <span class="ni">Module._call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1522</span> <span class="c1"># If we don&#39;t have any hooks, we want to skip the rest of the logic in</span>
<span class="g g-Whitespace">   </span><span class="mi">1523</span> <span class="c1"># this function, and just call forward.</span>
<span class="g g-Whitespace">   </span><span class="mi">1524</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_pre_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1525</span>         <span class="ow">or</span> <span class="n">_global_backward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1526</span>         <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1527</span>     <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1529</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1530</span>     <span class="n">result</span> <span class="o">=</span> <span class="kc">None</span>

<span class="nn">File ~/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py:114,</span> in <span class="ni">Linear.forward</span><span class="nt">(self, input)</span>
<span class="g g-Whitespace">    </span><span class="mi">113</span> <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">114</span>     <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>

<span class="ne">KeyboardInterrupt</span>: 
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>We now have a nice dataframe ready for export and annotation</p></li>
<li><p>For each sentence, we can label it as either:</p>
<ul>
<li><p>“start” - the start of a public comment section</p></li>
<li><p>“end” - the end of a public comment section</p></li>
<li><p>“other” - neither the start nor the end of a public comment section</p></li>
</ul>
</li>
<li><p>we can then export this dataframe to a csv file for annotation</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Save the dataframe to a CSV</span>
<span class="n">statements_for_annotation</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span>
    <span class="s2">&quot;public_comment_start_end_other_statements_for_annotation.csv&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>once the data has been annotated, we can then load it back into python and train a classifier</p></li>
<li><p>for a quick overview of the dataset, we can print the value counts of the labels</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">annotated_statements</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="s2">&quot;annotated_public_comment_start_end_other_statements.csv&quot;</span>
<span class="p">)</span>
<span class="n">annotated_statements</span><span class="o">.</span><span class="n">label</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>other    1181
start      93
end        50
Name: label, dtype: int64
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>lots and lots of examples of other</p></li>
<li><p>almost double the examples of start vs end</p></li>
<li><p>this is somewhat expected as there is a lot of administrative cruft that occurs before the start of a public comment section</p></li>
<li><p>and during annotation, we annotated any statement that seemed to be a part of that cruft as “start”</p></li>
</ul>
</section>
<section id="training-a-public-comment-period-start-and-end-classifier">
<h2>Training a Public Comment Period Start and End Classifier<a class="headerlink" href="#training-a-public-comment-period-start-and-end-classifier" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegressionCV</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_recall_fscore_support</span><span class="p">,</span> <span class="n">ConfusionMatrixDisplay</span>

<span class="c1"># Function for quickly training model and evaluating on test set</span>
<span class="k">def</span> <span class="nf">train_and_eval_model</span><span class="p">(</span>
    <span class="n">data</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">LogisticRegressionCV</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="n">ConfusionMatrixDisplay</span><span class="p">]:</span>
    <span class="c1"># Create train and test splits</span>
    <span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
        <span class="n">data</span><span class="p">[</span><span class="s2">&quot;sentence&quot;</span><span class="p">],</span>
        <span class="n">data</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">],</span>
        <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
        <span class="n">stratify</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">],</span>
    <span class="p">)</span>

    <span class="c1"># Create embedded text values</span>
    <span class="n">embedded_x_train</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">x_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">show_progress_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">embedded_x_test</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">x_test</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">show_progress_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Train model</span>
    <span class="n">trsfmr_clf</span> <span class="o">=</span> <span class="n">LogisticRegressionCV</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
    <span class="n">trsfmr_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">embedded_x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="c1"># Eval</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">trsfmr_clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">embedded_x_test</span><span class="p">)</span>
    <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">f1</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">precision_recall_fscore_support</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;weighted&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Precision: </span><span class="si">{</span><span class="n">precision</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">, Recall: </span><span class="si">{</span><span class="n">recall</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">, F1: </span><span class="si">{</span><span class="n">f1</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Confusion per label</span>
    <span class="n">matrix</span> <span class="o">=</span> <span class="n">ConfusionMatrixDisplay</span><span class="o">.</span><span class="n">from_predictions</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">trsfmr_clf</span><span class="o">.</span><span class="n">classes_</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">trsfmr_clf</span><span class="p">,</span> <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">f1</span><span class="p">,</span> <span class="n">matrix</span>

<span class="c1"># Train and eval model</span>
<span class="n">clf</span><span class="p">,</span> <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">f1</span><span class="p">,</span> <span class="n">matrix</span> <span class="o">=</span> <span class="n">train_and_eval_model</span><span class="p">(</span>
    <span class="n">annotated_statements</span>
<span class="p">)</span>

<span class="c1"># Print stats</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Precision: </span><span class="si">{</span><span class="n">precision</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">, Recall: </span><span class="si">{</span><span class="n">recall</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">, F1: </span><span class="si">{</span><span class="n">f1</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">matrix</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "e4db19a4048442ba96ed2d38dcdeab3c", "version_major": 2, "version_minor": 0}</script><script type="application/vnd.jupyter.widget-view+json">{"model_id": "f369ccc136f64c95a4f3c2c9f37f3a89", "version_major": 2, "version_minor": 0}</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Precision: 0.993, Recall: 0.992, F1: 0.992
Precision: 0.993, Recall: 0.992, F1: 0.992
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fcf7ea22a40&gt;
</pre></div>
</div>
<img alt="../../_images/ad03d17136e4407cffbd3bd1276fc49eec85a1de9aa38f2551632cf1cfd15868.png" src="../../_images/ad03d17136e4407cffbd3bd1276fc49eec85a1de9aa38f2551632cf1cfd15868.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Find the misclassified statements</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">annotated_statements</span><span class="p">[</span><span class="s2">&quot;sentence&quot;</span><span class="p">]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">annotated_statements</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span>
<span class="n">embedded_x_test</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">x_test</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">show_progress_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">embedded_x_test</span><span class="p">)</span>
<span class="n">misclassified</span> <span class="o">=</span> <span class="n">annotated_statements</span><span class="p">[</span><span class="n">y_test</span> <span class="o">!=</span> <span class="n">y_pred</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">misclassified</span><span class="p">[</span><span class="s2">&quot;pred&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_pred</span><span class="p">[</span><span class="n">y_test</span> <span class="o">!=</span> <span class="n">y_pred</span><span class="p">]</span>
<span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">misclassified</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;True: </span><span class="si">{</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">, Pred: </span><span class="si">{</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;pred&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">, Sentence: </span><span class="si">{</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;sentence&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "bf016098b82243bd93b14c738cdeab81", "version_major": 2, "version_minor": 0}</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True: end, Pred: start, Sentence: Seeing as we have no additional speakers present the public comment period is now open and we will move on to the next agenda item.
True: other, Pred: end, Sentence: Public comment period is open and closed.
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>These seem okay! Only two sentences are misclassified! And in both cases they seem odd.</p>
<ul>
<li><p>in one it seems like there may have been a typo or the speaker misspoke because they say “public comment period is now open” even though there are no speakers.</p></li>
<li><p>in the other, the speaker says “Public comment period is open and closed” which happens sometimes when no one signs up to speak.</p></li>
</ul>
</li>
<li><p>Granted, we didn’t use too much data and we have yet to test it on meetings outside of Seattle but this is a good start for us to use further</p></li>
</ul>
</section>
<section id="using-our-model-to-extract-public-comment-periods-from-meetings">
<h2>Using our model to extract public comment periods from meetings<a class="headerlink" href="#using-our-model-to-extract-public-comment-periods-from-meetings" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Now lets try and build a function to use this model to find public comment periods within a meeting</p></li>
<li><p>We will first classify each sentence in meeting using the classifer</p></li>
<li><p>Once we have found a sentence that is classified as a public comment period “start”, we will both, continue to look for further “start” sentences (as there may be later administrative cruft), additionally we will then look for the next sentence that is classified as a the “end” of a public comment period</p></li>
<li><p>we will then return the sentences between the last start and the first end</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_public_comment_periods</span><span class="p">(</span>
    <span class="n">transcript_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
    <span class="c1"># Read in the transcript</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">transcript_path</span><span class="p">)</span> <span class="k">as</span> <span class="n">open_f</span><span class="p">:</span>
        <span class="n">transcript</span> <span class="o">=</span> <span class="n">Transcript</span><span class="o">.</span><span class="n">from_json</span><span class="p">(</span><span class="n">open_f</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
    
    <span class="c1"># Init the list of public comment periods</span>
    <span class="n">pc_periods</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">last_open_index</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>

    <span class="c1"># Iter over sentences and classify each one with the open classifier</span>
    <span class="c1"># Once we have found a sentence that is classified as a public comment open</span>
    <span class="c1"># we will both, continue to look for future classifications of public comment open</span>
    <span class="c1"># (as there may be administrative cruft and we want the _last_ public comment open)</span>
    <span class="c1"># and we will start looking for the close statement</span>
    <span class="c1"># additionally, we will look for the close statement</span>
    <span class="c1"># once we find one, we will extract all of the sentences between the last open and the first close</span>
    <span class="c1"># as a single public comment period</span>

    <span class="c1"># note, there may be multiple public comment periods in a single meeting</span>
    <span class="c1"># so we will return a list of public comment periods</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">transcript</span><span class="o">.</span><span class="n">sentences</span><span class="p">):</span>
        <span class="c1"># Embed the sentence</span>
        <span class="n">embedded_sentence</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">sentence</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>

        <span class="c1"># Shape the embedded sentence for sklearn</span>
        <span class="n">embedded_sentence</span> <span class="o">=</span> <span class="n">embedded_sentence</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,:]</span>

        <span class="c1"># Predict if the sentence is a public comment open</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">embedded_sentence</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># If it is a public comment open</span>
        <span class="k">if</span> <span class="n">pred</span> <span class="o">==</span> <span class="s2">&quot;start&quot;</span><span class="p">:</span>
            <span class="c1"># Update the last open index</span>
            <span class="n">last_open_index</span> <span class="o">=</span> <span class="n">i</span>
        
        <span class="c1"># If we have seen a public comment open</span>
        <span class="k">elif</span> <span class="n">last_open_index</span> <span class="o">&gt;</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
            <span class="c1"># If it is a public comment close</span>
            <span class="k">if</span> <span class="n">pred</span> <span class="o">==</span> <span class="s2">&quot;end&quot;</span><span class="p">:</span>
                <span class="c1"># Get all the sentences between the last open and the close</span>
                <span class="n">pc_period</span> <span class="o">=</span> <span class="n">transcript</span><span class="o">.</span><span class="n">sentences</span><span class="p">[</span><span class="n">last_open_index</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
                <span class="c1"># Add the pc period to the list</span>
                <span class="n">pc_periods</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">s</span><span class="o">.</span><span class="n">text</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">pc_period</span><span class="p">])</span>
                <span class="c1"># Reset the last open index</span>
                <span class="n">last_open_index</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>

    <span class="k">return</span> <span class="n">pc_periods</span>

<span class="c1"># Try our function on a single random transcript</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">8</span><span class="p">)</span>
<span class="n">example_session</span> <span class="o">=</span> <span class="n">sessions</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">get_public_comment_periods</span><span class="p">(</span><span class="n">example_session</span><span class="o">.</span><span class="n">transcript_path</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;Okay, so we will go ahead and open the public comment period for now.&#39;,
 &#39;We will begin with Austin Miller.&#39;,
 &#39;Austin, please press Star six and go ahead.&#39;,
 &quot;Hello, Councilmembers, my name is Austin Miller, and I&#39;m Speking today on behalf of the Seattle restaurant alliance to share our support for CB 120092.&quot;,
 &#39;Without this, many platforms list restaurants without their knowledge.&#39;,
 &#39;Customers assume the restaurants have agreed to be listed of an delivery platform and will place blame on a restaurant for issues that arise with their order.&#39;,
 &#39;This can cause damage to their reputation and success.&#39;,
 &#39;By requiring that food delivery platforms operating in Seattle first obtain a written agreement with any restaurant prior to offering Take-Out or delivery services, this legislation will ensure the best customer experience with accurate pricing, menu options and the best quality food.&#39;,
 &#39;The Seattle restaurant alliance would like to thank Council President Gonzalez for her leadership on this issue.&#39;,
 &#39;Thank you.&#39;,
 &#39;Thank you, Iowa Austin.&#39;,
 &#39;Next we have Melissa Purcell.&#39;,
 &#39;Melissa, please press Star six and go ahead.&#39;,
 &#39;Hi, thank you very much.&#39;,
 &#39;My name is Melissa Purcell.&#39;,
 &quot;I&#39;m a prop master by trade in the film and commercial industry.&quot;,
 &quot;I&#39;m also the business agent of Istae local 48.&quot;,
 &#39;We represent the film members that work on film, television and commercial content.&#39;,
 &#39;Which in part is supposed to help the city determine if a film Commission was needed to support and grow the film industry.&#39;,
 &quot;In November of 2020, the city didn&#39;t recommend the creation of the Commission and in April they postponed that decision.&quot;,
 &#39;Today with complete due respect the Seattle music commissioners and Lgbtq commissioners who are about to be reinstated or sworn in--as recommended.&#39;,
 &#39;And as a compromise, the film task force will accept that a Commission may not be seated until the next Murgs but that the legislation be created now in order for the film industry to see that the city supports this need, especially as the city is deciding how to reorganize film and music and other creative industries and set priorities for recovery and support of our industry.&#39;,
 &#39;Thank you.&#39;,
 &#39;Thank you, Melissa.&#39;,
 &#39;Next we have Abby.&#39;,
 &quot;Abby, if you&#39;re with us, you&#39;ll need to push Star six so that we can hear you.&quot;,
 &#39;Abby, are you there?&#39;,
 &#39;I see you, but you are muted as far as I can tell.&#39;,
 &#39;Can you push Star six?&#39;,
 &#39;Okay.&#39;,
 &quot;Abby, you now appear Unmuted but we still can&#39;t hear you.&quot;,
 &#39;Oh, hello, can you hear me now?&#39;,
 &#39;There we go.&#39;,
 &#39;Okay.&#39;,
 &quot;Sorry, I don&#39;t--I don&#39;t understand why my phone was doing that.&quot;,
 &#39;Hello, everyone.&#39;,
 &#39;Thank you so much for giving me the time to comment today.&#39;,
 &#39;My name is Abby, and I am a writer and director in the Seattle film industry.&#39;,
 &quot;I&#39;m also a part of multiple organizations and events that are Film-Related here in the Seattle area.&quot;,
 &#39;And I have my own production company that helps to bring diverse voices to film and television.&#39;,
 &#39;Along with Melissa, I am a member of the Seattle film task force, which I was able to join early last year amongst the middle of the protests that I was involved in.&#39;,
 &quot;It was one of those situations that hearing the news that the film--Seattle film Commission wasn&#39;t going to be proceeded by the city, it was very upsetting to hear that.&quot;,
 &#39;And it felt like it was another situation where, you know, we as people of color are told that, you know, diversity and the like is going to be brought to our film industry.&#39;,
 &#39;And the Commission was supposed to help make sure that that was something to happen.&#39;,
 &#39;What is upsetting is that the fact that amongst all of the policy that we put together we were postponed, unsure when, not given an actual date of when we were supposed to come back or even have the option of bringing a Seattle film Commission.&#39;,
 &#39;And it is important to me along as a number of other Filmmakers in this area to make sure that that is considered, especially when you all are making your decisions.&#39;,
 &#39;Thank you very much for my time.&#39;,
 &#39;Thank you, Abby.&#39;,
 &#39;I do not see any other folks signed up.&#39;,
 &#39;Just want to confirm that.&#39;,
 &#39;There are no other public comment registrants.&#39;]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>This is great! It seems like we have a function which can extract public comment periods from meetings</p></li>
<li><p>Normally you would want to evaluate this function / method as well by annotating meetings but for now we will use it as is</p></li>
<li><p>Let’s extract the public comment periods from each meeting and save them to a new dataframe</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get all the public comment periods for all the transcripts</span>
<span class="n">all_pc_periods</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">session</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span>
    <span class="n">sessions</span><span class="o">.</span><span class="n">iterrows</span><span class="p">(),</span>
    <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">sessions</span><span class="p">),</span>
    <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Sessions&quot;</span><span class="p">,</span>
<span class="p">):</span>
    <span class="n">this_session_pc_periods</span> <span class="o">=</span> <span class="n">get_public_comment_periods</span><span class="p">(</span><span class="n">session</span><span class="o">.</span><span class="n">transcript_path</span><span class="p">)</span>
    
    <span class="c1"># Add a row to the dataframe for each public comment period</span>
    <span class="k">for</span> <span class="n">pc_period</span> <span class="ow">in</span> <span class="n">this_session_pc_periods</span><span class="p">:</span>
        <span class="n">all_pc_periods</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="s2">&quot;infra&quot;</span><span class="p">:</span> <span class="n">CDPInstances</span><span class="o">.</span><span class="n">Seattle</span><span class="p">,</span>
                <span class="s2">&quot;session_id&quot;</span><span class="p">:</span> <span class="n">session</span><span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">],</span>
                <span class="s2">&quot;pc_period&quot;</span><span class="p">:</span> <span class="n">pc_period</span><span class="p">,</span>
            <span class="p">}</span>
        <span class="p">)</span>

<span class="c1"># Convert to dataframe</span>
<span class="n">all_pc_periods</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">all_pc_periods</span><span class="p">)</span>
<span class="n">all_pc_periods</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sessions:   0%|          | 1/226 [00:02&lt;08:38,  2.30s/it]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>It seems like out of the original 226 sessions we gathered, we have 135 sessions with public comment periods</p></li>
<li><p>lets also calculate the mean number of public comment periods per meeting and find any meetings with multiple</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calculate mean number of public comment periods per session</span>
<span class="n">all_pc_periods</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;session_id&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">pc_period</span><span class="o">.</span><span class="n">count</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get dataframe of pc_periods for sessions that have multiple pc_periods</span>
<span class="n">sessions_with_multiple_pc_periods</span> <span class="o">=</span> <span class="n">all_pc_periods</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;session_id&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">pc_period</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
<span class="n">sessions_with_multiple_pc_periods</span> <span class="o">=</span> <span class="n">sessions_with_multiple_pc_periods</span><span class="p">[</span><span class="n">sessions_with_multiple_pc_periods</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">]</span>
<span class="nb">len</span><span class="p">(</span><span class="n">sessions_with_multiple_pc_periods</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>so it seems like there are only 10 sessions in our dataset with multiple public comment periods</p></li>
<li><p>this can happen but in Seattle is somewhat rare so this somewhat makes sense but again, we would want to evaluate this function further</p></li>
<li><p>the last thing we will do is to save the dataframe to a csv file for further analysis</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># save dataframe for next analysis</span>
<span class="n">all_pc_periods</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;all_pc_periods.csv&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./content/08"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#outline">Outline</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#coming-up-with-questions">Coming Up With Questions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#planning">Planning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#constructing-a-dataset-for-training-a-public-comment-period-start-and-end-classifier">Constructing a Dataset for Training a Public Comment Period Start and End Classifier</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-a-public-comment-period-start-and-end-classifier">Training a Public Comment Period Start and End Classifier</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-our-model-to-extract-public-comment-periods-from-meetings">Using our model to extract public comment periods from meetings</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Eva Maxfield Brown and Nic Weber
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>