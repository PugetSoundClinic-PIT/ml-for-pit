{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1aa7c6e5-1ae2-4464-9056-7062513607ea",
   "metadata": {},
   "source": [
    "# Counting Words\n",
    "\n",
    "Using the counts of words in a document is a good starting point for descriptive analysis, visualization, and predictive modeling. For example, counts of words is what makes up the data behind [Google Search Trends](https://trends.google.com/home) and the [Google NGram Viewer](https://books.google.com/ngrams/).\n",
    "\n",
    "Between search trends, ngram viewer, and more, the goal is to provide a broad picture as to what things are being discussed, searched, mentioned, etc.\n",
    "\n",
    "Applying this same idea to municipal legislative data, we might try understand what general topics are commonly discussed in a council via core words for a topic. For example, if the words \"housing\", \"rent\", and \"affordability\" are all spoken frequently in a city council meeting, we can broadly interpret that those three terms (and more general ideas about \"housing affordability\") were important topics of the meeting.\n",
    "\n",
    "So for this chapter, let's try to be able to **find and compare common topics discussed in a city council meeting, via word counts.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71faa09-7d81-43ee-9be5-dfc78a5f95df",
   "metadata": {},
   "source": [
    "## Let's Count\n",
    "\n",
    "Counting words is such a common task and is so heavily utilized that `scikit-learn` has a whole class for doing just that called [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14bf8427-933c-4110-a48f-0be2616fc66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x14 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 14 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create CountVectorizer object\n",
    "count_vec = CountVectorizer()\n",
    "\n",
    "# An example sentence we will count the words in\n",
    "example = \"Hello my name is Eva and I am commenting today in opposition of this bill.\"\n",
    "\n",
    "# Get counts\n",
    "counts = count_vec.fit_transform([example])\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1227e42-fa50-4e04-829d-eeaf33193162",
   "metadata": {},
   "source": [
    "Don't be afraid of the \"sparse matrix\" it is just an efficient storage mechanism that scikit-learn uses. We can see the results in a pandas dataframe too by doing the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "973ed0c3-8a81-4344-9e2f-06fb823c62d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>am</th>\n",
       "      <th>and</th>\n",
       "      <th>bill</th>\n",
       "      <th>commenting</th>\n",
       "      <th>eva</th>\n",
       "      <th>hello</th>\n",
       "      <th>in</th>\n",
       "      <th>is</th>\n",
       "      <th>my</th>\n",
       "      <th>name</th>\n",
       "      <th>of</th>\n",
       "      <th>opposition</th>\n",
       "      <th>this</th>\n",
       "      <th>today</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   am  and  bill  commenting  eva  hello  in  is  my  name  of  opposition  \\\n",
       "0   1    1     1           1    1      1   1   1   1     1   1           1   \n",
       "\n",
       "   this  today  \n",
       "0     1      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "counts_df = pd.DataFrame(\n",
    "    counts.toarray(),  # convert from sparse matrix to numpy\n",
    "    columns=count_vec.get_feature_names_out(),  # store words as the column names\n",
    ")\n",
    "counts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c2d227-7ddd-4aa9-8603-6db09afaa980",
   "metadata": {},
   "source": [
    "Let's take a moment to notice that all of the words have been lowercased.\n",
    "\n",
    "There are many decisions to make when counting and we recommend you view the documentation for [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) to see all of the options but we will highlight a few throughout the rest of this chapter.\n",
    "\n",
    "First, as already noted, lowercasing is something you can enable or disable. It depends on how specific you want your counts to be, do you want \"House\" and \"house\" to be counted separately? The only difference between the two might be that one is the first word in a sentence, but there are many other cases where casing is important to keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7631556-e935-48f1-93e3-9df73b2b7acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Eva</th>\n",
       "      <th>Hello</th>\n",
       "      <th>am</th>\n",
       "      <th>and</th>\n",
       "      <th>bill</th>\n",
       "      <th>commenting</th>\n",
       "      <th>in</th>\n",
       "      <th>is</th>\n",
       "      <th>my</th>\n",
       "      <th>name</th>\n",
       "      <th>of</th>\n",
       "      <th>opposition</th>\n",
       "      <th>this</th>\n",
       "      <th>today</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Eva  Hello  am  and  bill  commenting  in  is  my  name  of  opposition  \\\n",
       "0    1      1   1    1     1           1   1   1   1     1   1           1   \n",
       "\n",
       "   this  today  \n",
       "0     1      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And example of turning off lowercasing\n",
    "count_vec_no_lowercase = CountVectorizer(lowercase=False)\n",
    "pd.DataFrame(\n",
    "    count_vec_no_lowercase.fit_transform([example]).toarray(),\n",
    "    columns=count_vec_no_lowercase.get_feature_names_out(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e70be1-4407-4fed-89c5-fcf217b8e44d",
   "metadata": {},
   "source": [
    "## Ngrams\n",
    "\n",
    "Second, all of the words are counted individually. I.e. a single word, gets a single count. What if we want to track pairs of words, or even three word groups, what about `N`-word-groups? This is the idea behind n-grams: contiguous sequence of `n` items from a given sample of text or speech. The items can be words, letters, syllables, etc.\n",
    "\n",
    "For example, this type of tracking might be useful when we want to look for \"housing affordability\" as a single item instead of \"housing\" and \"affordability\" as separate items.\n",
    "\n",
    "We can use `CountVectorizer` to construct any range of ngrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9e0392-289c-42a8-a3bd-49ba2dff72c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>am</th>\n",
       "      <th>am commenting</th>\n",
       "      <th>am commenting today</th>\n",
       "      <th>and</th>\n",
       "      <th>and am</th>\n",
       "      <th>and am commenting</th>\n",
       "      <th>bill</th>\n",
       "      <th>commenting</th>\n",
       "      <th>commenting today</th>\n",
       "      <th>commenting today in</th>\n",
       "      <th>...</th>\n",
       "      <th>of this</th>\n",
       "      <th>of this bill</th>\n",
       "      <th>opposition</th>\n",
       "      <th>opposition of</th>\n",
       "      <th>opposition of this</th>\n",
       "      <th>this</th>\n",
       "      <th>this bill</th>\n",
       "      <th>today</th>\n",
       "      <th>today in</th>\n",
       "      <th>today in opposition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   am  am commenting  am commenting today  and  and am  and am commenting  \\\n",
       "0   1              1                    1    1       1                  1   \n",
       "\n",
       "   bill  commenting  commenting today  commenting today in  ...  of this  \\\n",
       "0     1           1                 1                    1  ...        1   \n",
       "\n",
       "   of this bill  opposition  opposition of  opposition of this  this  \\\n",
       "0             1           1              1                   1     1   \n",
       "\n",
       "   this bill  today  today in  today in opposition  \n",
       "0          1      1         1                    1  \n",
       "\n",
       "[1 rows x 39 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Allow unigrams to trigrams (1 word to 3 word items)\n",
    "count_vec_uni_tri = CountVectorizer(ngram_range=(1, 3))\n",
    "pd.DataFrame(\n",
    "    count_vec_uni_tri.fit_transform([example]).toarray(),\n",
    "    columns=count_vec_uni_tri.get_feature_names_out(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786e438e-f3d9-41b5-a6ab-7b1d3fe91854",
   "metadata": {},
   "source": [
    "Note: as you increase your ngram range, you gain specificity at the cost of memory because you simply have to keep track of many more distinct grams."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9869315-7e09-49e6-b40b-0d18caed2536",
   "metadata": {},
   "source": [
    "## Working With Transcript Data\n",
    "\n",
    "To get a better understanding of how to work with count data, let's use city council meeting transcript data made available by Council Data Project.\n",
    "\n",
    "To do so, let's first pull a small sample of meeting data, read the transcripts, and construct ngram counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539c8f55-fe29-4700-9a71-e28522506d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cdp_data import CDPInstances, datasets\n",
    "\n",
    "df = datasets.get_session_dataset(\n",
    "    CDPInstances.Seattle,\n",
    "    start_datetime=\"2020-01-01\",\n",
    "    end_datetime=\"2021-01-01\",\n",
    "    store_transcript=True,\n",
    "    store_transcript_as_csv=True,\n",
    "    raise_on_error=False,\n",
    ")\n",
    "df.columns, df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3a992e-79a4-46de-ba1b-6ebae957cfea",
   "metadata": {},
   "source": [
    "## STOPPING HERE FOR NOW. CONTINUE LATER"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c702b79-4a9b-44f3-ab8c-0134a3ad41ce",
   "metadata": {},
   "source": [
    "# How to Count Words\n",
    "\n",
    "Lets use a single transcript for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a91484-fa7a-4b47-b0f3-055ac30fd4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "example_session = pd.read_csv(df.iloc[0].transcript_as_csv_path)\n",
    "example_session"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2657d337-8af3-4838-a860-c1d347d73b66",
   "metadata": {},
   "source": [
    "### Scikit Learn Count Vectorizer\n",
    "\n",
    "If we want to track word counts over time, what we want is a large matrix of events and counts\n",
    "\n",
    "Sort of like so:\n",
    "\n",
    "| session_id | session_datetime | word | count |\n",
    "|:-----------|:-----------------|:-------|:----|\n",
    "| abcd-1234  | 2020-01-01       | hello  | 4   |\n",
    "| abcd-1234  | 2020-01-01       | world  | 2   |\n",
    "| ...        | ...              | ...    | ... |\n",
    "| abcd-1234  | 2020-01-01       | ramen  | 2   |\n",
    "\n",
    "Scikit Learn (`sklearn`) has a function to make that somewhat simple. We just need to combine all of the text for a single session into a single string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d9a40a-9ffc-4a87-aabd-06bb3376b4e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "all_session_text = \" \".join(example_session.text)\n",
    "counts = vectorizer.fit_transform([all_session_text])\n",
    "vectorizer.get_feature_names_out()[:20]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a47c74d3-2b75-4e97-b478-5d3ee41fed35",
   "metadata": {},
   "source": [
    "## Words?\n",
    "\n",
    "The `CountVectorizer` includes all text, so we can see that some of the items counted were numbers and some were words. If we wanted to see their counts we can combine them.\n",
    "\n",
    "Looks like \"able\" and \"about\" were both used 12 and 11 times respectively. Let's do this counting process for all of the meetings and store the data to a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c6c02c-a09e-4263-a0dd-a3b695a06399",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for word, count in zip(\n",
    "    vectorizer.get_feature_names_out()[:20],\n",
    "    list(counts[0, :20].toarray()[0]),\n",
    "):\n",
    "    print(f\"'{word}' was used {count} times in the meeting\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "997fcf75-1eb3-4ecb-a519-32be6b90379d",
   "metadata": {},
   "source": [
    "## Pass In All Documents At Once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950cd13f-07f8-4086-bf39-9784994c1a8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "texts = []\n",
    "for i, row in df.iterrows():\n",
    "    session_transcript = pd.read_csv(row.transcript_as_csv_path)\n",
    "    try:\n",
    "        texts.append({\n",
    "            \"session_id\": row.id,\n",
    "            \"session_datetime\": row.session_datetime,\n",
    "            \"session_text\": \" \".join(session_transcript.text),\n",
    "        })\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "text_df = pd.DataFrame(texts)\n",
    "text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3304a123-02f0-4831-833b-3d367e89d2a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "counts = vectorizer.fit_transform(text_df.session_text)\n",
    "count_df = pd.DataFrame(counts.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "count_df[\"session_id\"] = text_df[\"session_id\"]\n",
    "count_df[\"session_datetime\"] = text_df[\"session_datetime\"]\n",
    "count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdc1051-1b82-4328-9c36-382af5490cd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "count_df = count_df.melt(id_vars=[\"session_id\", \"session_datetime\"], var_name=\"word\", value_name=\"word_count\")\n",
    "count_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aac65485-3774-40ed-b792-a878084ebe74",
   "metadata": {},
   "source": [
    "## Most Common Words (Average Across All Meetings)\n",
    "\n",
    "Filler words are the most common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11655460-2210-4654-a32f-0f32ac69e723",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "count_df.groupby(\"word\")[\"word_count\"].mean().nlargest(20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a334bbc-1910-4986-a790-64ce00fa074d",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1e1ab8-0f07-479f-a628-9254cbb4a7f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "# Select the word we are interested in\n",
    "housing_counts = count_df[count_df[\"word\"] == \"housing\"]\n",
    "\n",
    "# Plot the responses for different events and regions\n",
    "sns.lineplot(\n",
    "    x=\"session_datetime\",\n",
    "    y=\"word_count\",\n",
    "    data=housing_counts,\n",
    ")\n",
    "_ = plt.xticks(rotation=35, ha=\"right\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e9a22bc-4718-4759-b8b4-e50ff8470f29",
   "metadata": {},
   "source": [
    "## Why Is This Deceptive?\n",
    "\n",
    "1. Meetings are different length. One meeting might be longer and therefore have more words overall.\n",
    "2. Discussion doesn't happen every day. Need to smooth it out somehow.\n",
    "3. \"Housing\" doesn't include \"house\", \"houses\", etc."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21e095d0-af63-40ea-b71f-72bfaa94522a",
   "metadata": {},
   "source": [
    "## Possible Solution: Make Each Word Count a \"Percentage\" of Total Words for The Meeting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f984c031-072f-48f9-b2a9-327fcf5804cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "count_df[\"percent_use_in_meeting\"] = count_df[\"word_count\"] / count_df.groupby(\"session_id\")[\"word_count\"].transform(\"sum\")\n",
    "count_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "74d6742c-5461-474c-b684-2c4d011d8f6c",
   "metadata": {},
   "source": [
    "## Replot\n",
    "\n",
    "Interpret: The y-axis is now \"percent usage of this word in each session\" i.e. if the value is ~0.01 that means that the word was used 1% of the time (or about 1/100 words used in the meeting was \"housing\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3529530e-c96d-4646-9c1c-fe69ad4ba36a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select the word we are interested in\n",
    "housing_counts = count_df[count_df[\"word\"] == \"housing\"]\n",
    "\n",
    "# Plot the responses for different events and regions\n",
    "sns.lineplot(\n",
    "    x=\"session_datetime\",\n",
    "    y=\"percent_use_in_meeting\",\n",
    "    data=housing_counts,\n",
    ")\n",
    "_ = plt.xticks(rotation=35, ha=\"right\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3de144e2-7781-48b3-9b6c-bb278601e2ea",
   "metadata": {},
   "source": [
    "## Possible Solution: Rolling Mean Over One Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6f26ce-5ff0-46b5-9a1b-f64f9b4a5833",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rolling_30_days = count_df.set_index(\"session_datetime\").sort_index(ascending=True).groupby(\"word\").rolling(\"30D\").agg({\n",
    "    \"percent_use_in_meeting\": \"mean\"\n",
    "}).reset_index()\n",
    "rolling_30_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dbc86f-098e-4cf4-941f-049bb6f25002",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select the word we are interested in\n",
    "housing_counts = rolling_30_days[rolling_30_days[\"word\"] == \"housing\"]\n",
    "\n",
    "# Plot the responses for different events and regions\n",
    "sns.lineplot(\n",
    "    x=\"session_datetime\",\n",
    "    y=\"percent_use_in_meeting\",\n",
    "    data=housing_counts,\n",
    ")\n",
    "_ = plt.xticks(rotation=35, ha=\"right\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4efd25c8-4e6a-4adb-ab32-e6860ec772df",
   "metadata": {},
   "source": [
    "## Possible Solution: Stem Each Word Prior to Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef80c8fa-7933-4dac-8927-d56c6520da7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select the word we are interested in\n",
    "housing_counts = rolling_30_days[rolling_30_days[\"word\"].isin([\"housing\", \"house\", \"houses\"])]\n",
    "\n",
    "# Plot the responses for different events and regions\n",
    "sns.lineplot(\n",
    "    x=\"session_datetime\",\n",
    "    y=\"percent_use_in_meeting\",\n",
    "    hue=\"word\",\n",
    "    data=housing_counts,\n",
    ")\n",
    "_ = plt.xticks(rotation=35, ha=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e2b11f-91aa-4c8b-97ea-22ad16df5939",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
