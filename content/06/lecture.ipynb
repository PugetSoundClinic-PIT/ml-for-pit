{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 6 -- Pre-trained Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "* in many cases, training your own model may be the best thing you can do as you have full control over the data, training, and the evaluation process.\n",
    "\n",
    "* however, this lecture will go over pre-trained models and more generally, models that are freely available for you to use.\n",
    "\n",
    "* pretrained and freely available models have become incredibly common and are often a good starting point for experimentation and more.\n",
    "\n",
    "* we will go over a few examples of pretrained models and how to use them including models for:\n",
    "    * sentiment analysis\n",
    "    * summarization\n",
    "    * named entity recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalization vs Specialization\n",
    "\n",
    "* in the prior chapter we talked about how for some tasks we need to train our own model because we want to define the annotation criteria or we are in a very niche sub-domain.\n",
    "\n",
    "* however, using pre-trained models that are general to a task can also be quite useful -- especially considering that they were likely trained with more data than the dataset you are working with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers and Huggingface\n",
    "\n",
    "* We have introduced and used transformers, a model architecture\n",
    "\n",
    "* huggingface is a company which builds tools around various model architectures to make them easily shareable\n",
    "\n",
    "* for example, here is a link to their website in which you can search and browse for available models: https://huggingface.co/models\n",
    "* every single model is available for download and use and in many cases has some documentation attached to understand how to use the model in your own work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "* sentiment analysis is a task in which we want to predict the sentiment of a text\n",
    "* sentiment is often defined as positive, negative, or neutral\n",
    "* for example, the phrase: \"I love this movie\" would be positive and \"I hate this movie\" would be negative\n",
    "\n",
    "* sentiment analysis is a very common task and there are many datasets available for it\n",
    "* for example, here is a dataset of movie reviews: https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
    "\n",
    "* there are many models available for sentiment analysis on huggingface (and elsewhere) but for our examples, we will use:\n",
    "\"cardiffnlp/twitter-roberta-base-sentiment-latest\" (https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest)\n",
    "  * this model was trained on millions of pairs of sentiment labeled tweets\n",
    "\n",
    "* lets load the model and try it on a few examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
    ")\n",
    "\n",
    "# Predict sentiment of the statement\n",
    "model(\"I am happy to see that other members of the council are supporting this important legislation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* we can see that for the phrase `\"I am happy to see that other members of the council are supporting this important legislation.\"` the model predicts a positive sentiment and given a score\n",
    "\n",
    "* you can interpret the `score` value as the model's confidence in the prediction\n",
    "* the higher the score, the more confident the model is in the prediction (in this case, the model is very confident that the sentiment is positive)\n",
    "\n",
    "* lets try a few more examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the model multiple examples at once by providing a list\n",
    "model([\n",
    "    \"I urge the members of the committee to vote against this bill.\",\n",
    "    (\n",
    "        \"If the amendment from Councilmember Brown passes, I will vote in support of this legislation. \"\n",
    "        \"But without the amendment, I cannot agree to move forward with this legislation.\"\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This time we can see that the model is confident that the sentiment of the first example (`\"I urge the members of the committee to vote against this bill.\"`) is negative and the second example (`\"But without the amendment, I cannot agree to move forward with this legislation.\"`) is neutral.\n",
    "\n",
    "* This makes sense to me, as the second example is specifically discussing conditions of agreement or disagreement which places it somewhere in a neutral category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations and Warnings\n",
    "\n",
    "* Sentiment can be subjective and it is important to understand the limitations of the model and the data it was trained on, and who annotated the data.\n",
    "\n",
    "* The model we used for sentiment was trained using twitter data -- twitter posts are obviously different than meeting discussion\n",
    "\n",
    "* this can affect the model and we should always evaluate the performance of even off the shelf models\n",
    "\n",
    "* in general, when using a model, be sure to read how it was trained, what data it used for training, and understand the possible biases and problems that come from using a model trained by someone else\n",
    "\n",
    "* try to find a model that was trained on data close to yours for the best results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarization\n",
    "\n",
    "* summarization can be an important task for processing long documents such as multiple hour long meeting transcripts\n",
    "\n",
    "* there can be direct reader benefits by trying to extract or explain the main points of a meeting for example\n",
    "\n",
    "* using generated summaries can also be useful for other tasks such as information retrieval (i.e. instead of searching across the whole meeting, you can search across the summary), or for other situations in which you simply can't fit the whole meeting into memory of the model but can fit the summary\n",
    "\n",
    "* the two main types of summarization are extractive and abstractive\n",
    "\n",
    "* extractive summarization is when you extract sentences from the original document and combine them to form a summary\n",
    "\n",
    "* abstractive summarization is when you generate new sentences that are not in the original document to form a summary\n",
    "\n",
    "* someone has already taken the time to train a model for meeting dialoge summarization: https://huggingface.co/knkarthick/MEETING_SUMMARY\n",
    "\n",
    "* lets use this model to generate a summary for a meeting\n",
    "\n",
    "* first lets pull down some data and prep the data for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88afa1650c0a4b1f9c896c8a7167f4bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching each model attached to event_ref:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4106c0e2cd3749bd83688255d2e15def",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching transcripts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d176e5148d344f97a6a05c94f879d4a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting transcripts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "855"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cdp_data import CDPInstances, datasets\n",
    "import pandas as pd\n",
    "\n",
    "sessions = datasets.get_session_dataset(\n",
    "    CDPInstances.Seattle,\n",
    "    start_datetime=\"2022-05-01\",\n",
    "    end_datetime=\"2022-05-03\",\n",
    "    store_transcript=True,\n",
    "    store_transcript_as_csv=True,\n",
    ")\n",
    "\n",
    "single_session_transcript = pd.read_csv(sessions.iloc[0].transcript_as_csv_path)\n",
    "len(single_session_transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because are meetings are incredibly long\n",
    "# lets create a strings with different portions of the meeting\n",
    "# to pass to the model\n",
    "parts = []\n",
    "n_sentences_per_chunk = 30\n",
    "for index in range(\n",
    "    0,\n",
    "    len(single_session_transcript),\n",
    "    n_sentences_per_chunk,\n",
    "):\n",
    "    parts.append(\n",
    "        \" \".join(\n",
    "            single_session_transcript.iloc[index:index+n_sentences_per_chunk].text\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* now that we have multiple chunks, lets first pass in just the first chunk to the model and see what it generates\n",
    "\n",
    "\n",
    "For reference, here is the full text of the first chunk:\n",
    "\n",
    "> \"I will call the roll on May 2nd. May 2nd, 2022 Council briefing meeting will come to order. I am Andrew Lewis, Council President pro tem. The time is 2.01 p.m. Will the clerk please call the roll? Councilmember Wilson? Present. Councilmember Peterson? Present. Councilmember Sawant? Present. Councilmember Strauss? Present. Councilmember Herbold? Present. Councilmember Williams? Present. Councilmember Gattas? Present. Councilmember Herbold? Here. Councilmember Morales? Present. Councilmember Pro Tem Lewis? Present. Six present. Thank you. We will move on to approval of the minutes. If there is no objection, the minutes of May 2nd, 2022 will be adopted. Hearing no objection, the minutes are adopted. The President's report. I will call the roll on May 2nd, 2022 Council briefing meeting will come to order. I am Andrew Lewis, Council President pro tem. The time is 2.01 p.m. Will the clerk please call the roll? Councilmember Wilson? Present. Councilmember Peterson? Present. Councilmember Sawant? Present. Councilmember Peterson? Present. Councilmember Herbold? Here. Councilmember Morales? Present. Councilmember Gattas? Present. Councilmember Herbold? Present. Councilmember Gattas? Present. I am filling in. As folks may be aware for Council President Juarez. I do not have any. Reports at the top of the meeting. Except to give a brief preview of the full council. Agenda that we will be considering. As a council tomorrow.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06c2c7759ec648a78b25d8d77e2dad77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.59k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db69a0f13402408987433213f495da70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14aa345e57b649c38413c1e497d3272b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/337 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "413cf8f613a94243930a8b636e130f08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5aa360348c141d6aecfe83d121432d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df98439c38424626abfffdb01b5b0fec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a1fa6b714074acfbf39eccbe92f13b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'Andrew Lewis, Council President pro tem, will call the roll on May 2nd, 2022 Council briefing meeting. If there is no objection, the minutes are adopted.'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "summarizer = pipeline(\"summarization\", model=\"knkarthick/MEETING-SUMMARY-BART-LARGE-XSUM-SAMSUM-DIALOGSUM-AMI\")\n",
    "\n",
    "# Summarize the first part of the meeting\n",
    "summarizer(parts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can see that the summary is short and to the point and generally captures the main idea of this chunk. Which is simply that the meeting has begun roll call took place.\n",
    "\n",
    "* However it is definitely missing some specificity and details that would be useful for a reader.\n",
    "\n",
    "* Lets summarize the rest of the chunks and see what we get back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [05:19<00:00, 11.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andrew Lewis, Council President pro tem, will call the roll on May 2nd, 2022 Council briefing meeting. If there is no objection, the minutes are adopted.\n",
      "\n",
      "Andrew Lewis, Council President pro tem, will call the roll on May 2nd, 2022 Council briefing meeting. The President's report will be presented at the top of the meeting.\n",
      "\n",
      "The agenda for tomorrow's full council meeting is going to be the same as the agenda for the previous meeting. The agenda includes several ordinances, several appointments, the appointment of Gail Tarleton as director of the office of intergovernmental relations, and other ordinances related to the Wagner floating home\n",
      "\n",
      "I'm pleased to be presenting a resolution in partnership with the mayor's office commemorating national small business week in Seattle. As the first small business owner on the council in over 10 years, I'm excited and proud to celebrate the over 100,000 small businesses that call Seattle home.\n",
      "\n",
      "The clerk calls the roll to determine which council members will be included in the 2021. Council member Nelson, Council member Peterson, Council members Herbold, Council president pro-tem Lewis, and Council member Morales will be a fixed to the proclamation. They will now move on to the next proclamation\n",
      "\n",
      "Scott was an activist and organizer in Seattle. He helped found share in 1990 and Nicholsville in 2008. Rich Campbell at the Keystone United church of Christ in Seattle road, a moving recollection of Scott's impact that has been distributed on social media. Scott called me one Saturday and asked if they\n",
      "\n",
      "The clerk asks Council member Nelson to call the role to determine which council members would like to be called for today. Council member Strauss, Council member Morales, and Council president pro-tem Lewis agree. The clerk asks them to revisit the approval of the minutes.\n",
      "\n",
      "The minutes are adopted. The roll call will be a rotating roll call with the council members Nelson, Juarez, Mosqueda, Peterson, and Sawant.\n",
      "\n",
      "Nelson, Herbold, Council member Morales, Council President pro-tem Lewis, and Council member Nelson discuss a resolution to address SPDs increasingly dire staffing shortage at the April 26th public safety and human services committee. Nelson thinks it's important to remember that this is a bill that states\n",
      "\n",
      "If council passed the resolution, then we could move fairly quickly on to lifting or modifying the budget proviso, and we'd approve the specifics of the incentive program by a separate ordinance as well, pretty much in tandem with that and with that action. If council rejected the, the resolution\n",
      "\n",
      "I want to talk about some of the things that happened last week and I hope that this answers questions about why I'm doing this by resolution and I'm looking forward to to to our second discussion in the may 10th public safety committee and possible vote out of committee and then welcoming my\n",
      "\n",
      "There are no items from the committee on transportation and Seattle public utilities. Tomorrow's introduction and referral calendar will include Andrew Lee's nomination of Andrew Lee to be the permanent general manager and CEO of Seattle Public Utilities. The next committee meeting is on Tuesday, May 17 at 9:30 AM\n",
      "\n",
      "Tomorrow's city council agenda from sustainability and renters rights committee is cancelled. The next meeting of the committee will be held on 20th at nine 30 AM. At that meeting, they expect to hear the information on electrifying the dredge trucks that call in and out of the port of Seattle\n",
      "\n",
      "Last week in district six, we had a new enrollment opportunity for the Seattle Central College. Now is the time to enroll in the maritime Academy. I also had the opportunity to speak to the green lake chamber of commerce is monthly meeting. I continue my work with the mayor's office, including\n",
      "\n",
      "At this point, nearly everyone on the by-name list has been offered their preferred shelter option. And as of April 21st, we've moved at least 30 people inside and we are still actively moving people inside. And while we focus our effort, we're still working with the\n",
      "\n",
      "This week in district six, I'll be hosting a meeting with Tom Fain, Rick Sheridan, the managers of two safe ways in D six, and the district manager, my staff will attend the Ballard Avenue historic commission meeting to discuss the improvements. I will also be hosting weekly office hours with D\n",
      "\n",
      "On May 29th 1907, the mayor of Ballard was concerned that annexation would affect Ballard's reputation to the rest of the country. The mayor's veto of the curfew ordinance was overridden by the Ballard city council. The town Marshal was to ring the firebell each night to signal\n",
      "\n",
      "I'll be attending my monthly meeting with Kendi Yamaguchi and I'll be meeting with Seattle department of construction inspections. I look forward to meeting with you and the land use committee here at Seattle city hall, and I'm going to turn it over to council members to have five agenda items\n",
      "\n",
      "On the full council agenda for tomorrow, we do have a public safety and human services committee. The next item on the agenda is public hearing for council bill 12, 0 2 94, otherwise known as the pay up legislation on minimum compensation, transparency, and flexibility. The full council meetings\n",
      "\n",
      "There are 77% of older people who want to live independently and grow old in the home or community of their choice. The city has provided support for efforts that help seniors meet that goal.\n",
      "\n",
      "The city of Seattle is proud to be a part of the older American month, which encourages older Americans to stretch, not rest on their laurels. The city is committed to the overarching goal of an age friendly Seattle to enable all people and abilities to achieve.\n",
      "\n",
      "I was a little late to council member Nelson's committee because I was giving testimony at the King County Council's budget. And I was at the committee meeting testify in support of a new facility. And as chair of the committee with oversight of human services and public health, I want to\n",
      "\n",
      "On Thursday, I participated in the search committee meeting for the new OPA director. On Monday I had regular meetings with both the CPC and the police commission. On Wednesday, I'll also be attending a reception for the Atlantic street center and Novices changing minds event. On Friday, I\n",
      "\n",
      "I understand that you asked council president Juarez to expedite getting your bill onto this week's IRC and she declined. So I'm going to ask you to make it clear to me that what you're pushing legislation through without going through the proper channels, I believe is bad governance.\n",
      "\n",
      "I put forward an alternative piece of legislation, but you didn't allow me to talk about it until 45 minutes into a 60-minute discussion. I learned that you also had a council bill again, in committee. I would rather we not have a debate right now in council briefing about\n",
      "\n",
      "At the last meeting of the neighborhood education, arts and civil rights committee on April 22nd , we approved two appointments for the Seattle arts commission to be on the consent agenda for tomorrow's full council meeting , we also passed two landmark preservation ordinances . Um, at the last committee meeting ,\n",
      "\n",
      "This Wednesday at noon, we'll be discussing and voting on two appointments from Pike place market historical commission and from the Pike Place market PDA council . Um , last week, uh , in terms of external committees , I attended the King County growth management planning council , uh , for your information .\n",
      "\n",
      "This week I will be attending the Puget Sound regional council's growth meeting, I will also be attending South End Village on May 5th, I believe. And then lastly, um , I'm excited to say that along with the coalition of about 30 community partners, uh , this\n",
      "\n",
      "On May 6th in the spirit, uh, council member Nelson of, of small business week, my staff and I are going to be visiting, um, Noir Lux candle company in bell town. On the same day, I'm also going to visit a new social justice incubator in Melbourne tower\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "results = []\n",
    "for part in tqdm(parts):\n",
    "    summary = summarizer(part)[0][\"summary_text\"]\n",
    "    results.append(summary)\n",
    "\n",
    "print(\"\\n\\n\".join(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This looks okay. There are some details about what is happening during this meeting, and as this meeting is a \"briefing meeting\" it explains what major agenda items and actions are on each of the council member's schedules for the rest of the week.\n",
    "\n",
    "* There are some problems, in a few places this lacks specificity and detail. In many cases, the summary is cut off at the end because the model has a limit on the number of tokens it generates (this is solvable via the `max_new_tokens` parameter if we really want to work to fix it: https://huggingface.co/docs/transformers/main_classes/pipelines#transformers.ImageToTextPipeline.__call__)\n",
    "\n",
    "* Similarly, it seems like there are some pieces of information duplicated across summary portions. This is likely happening because the chunks we are passing in are so small. There may be a single discussion item happening across chunks and the model is generating a summary for each chunk and thus duplicating information.\n",
    "\n",
    "* However, this is a good starting point and we can see that the model is able to generate summaries that capture some of the main ideas or at least discussion points of the meeting and drastrically reduce it's size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations and Warnings\n",
    "\n",
    "* it is important to note again that while this reduced the meeting into a few paragraphs of detail, it doesn't include all of the details and context that a reader may need or want\n",
    "\n",
    "* further, just like with sentiment, the data used for training the model may be different than the data you are using it on\n",
    "\n",
    "* one of the larger limitations which we might begin to resolve in the next lecture is that this model is relatively small. It can easily fit on most laptops and desktops, and can easily run within Google Colab. However it is not as powerful as some of the larger models that are available that excel at summarization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy\n",
    "\n",
    "* spacy is a different library than huggingface's transformer's but one which similarly provides a whole suite of tools for NLP\n",
    "* it comes pre-packages with tools ready for use such as tokenization, named entity recognition, and more.\n",
    "    * see the documentation for more details: https://spacy.io/usage/spacy-101#features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* the first thing to do prior to using spacy is to download the model you want to use\n",
    "\n",
    "* they have a few models available for english language text:\n",
    "    * `en_core_web_sm`  a very small model which is very fast to use but may be less accurate\n",
    "    * `en_core_web_lg`  a larger model which is slower to use but may be more accurate\n",
    "    * `en_core_web_trf`  a transformer based model which is slower to use but may be more accurate\n",
    "\n",
    "* in general, if we want to accuracy in our model predictions, it is recommended to use `en_core_web_trf`\n",
    "\n",
    "* lets download the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 10:39:29.456285: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-01 10:39:29.701006: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-01 10:39:29.701098: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-01 10:39:29.748816: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-01 10:39:29.844343: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-01 10:39:30.827729: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-12-01 10:39:32.249004: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-01 10:39:32.250204: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "Collecting en-core-web-trf==3.7.3\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_trf-3.7.3/en_core_web_trf-3.7.3-py3-none-any.whl (457.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m457.4/457.4 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from en-core-web-trf==3.7.3) (3.7.2)\n",
      "Requirement already satisfied: spacy-curated-transformers<0.3.0,>=0.2.0 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from en-core-web-trf==3.7.3) (0.2.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (2.4.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (2.0.8)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (0.7.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (1.10.8)\n",
      "Requirement already satisfied: jinja2 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (67.7.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (1.24.3)\n",
      "Requirement already satisfied: curated-transformers<0.2.0,>=0.1.0 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (0.1.1)\n",
      "Requirement already satisfied: curated-tokenizers<0.1.0,>=0.0.7 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (0.0.8)\n",
      "Requirement already satisfied: torch>=1.12.0 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (2.0.1)\n",
      "Requirement already satisfied: regex>=2022 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from curated-tokenizers<0.1.0,>=0.0.7->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (2023.5.5)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (4.6.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (2023.5.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (0.0.4)\n",
      "Requirement already satisfied: filelock in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (3.12.0)\n",
      "Requirement already satisfied: sympy in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (1.12)\n",
      "Requirement already satisfied: networkx in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (2.0.0)\n",
      "Requirement already satisfied: wheel in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (0.40.0)\n",
      "Requirement already satisfied: cmake in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (3.26.3)\n",
      "Requirement already satisfied: lit in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (16.0.5)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (8.1.3)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/eva/miniforge-pypy3/envs/ml-for-pit/lib/python3.10/site-packages (from sympy->torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (1.3.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_trf')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_trf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now lets load the model into spacy and try out some basic operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I \t\t PRON\n",
      "will \t\t AUX\n",
      "call \t\t VERB\n",
      "the \t\t DET\n",
      "roll \t\t NOUN\n",
      "on \t\t ADP\n",
      "May \t\t PROPN\n",
      "2nd \t\t NOUN\n",
      ". \t\t PUNCT\n",
      "May \t\t PROPN\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the model\n",
    "nlp = spacy.load(\"en_core_web_trf\")\n",
    "\n",
    "# Create a spacy \"Document\" object using the full text of the transcript joined together as a single string\n",
    "doc = nlp(\" \".join(single_session_transcript.text))\n",
    "\n",
    "# show the first couple of \"tokens\" in the document and the part of speech (POS) tag for each\n",
    "for token in doc[:10]:\n",
    "    print(token.text, \"\\t\\t\", token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Spacy gives us a lot of fine-grained information about each \"token\" (word) in the text, including the part of speech\n",
    "\n",
    "* in this case, we can see that \"call\" is a verb, \"May\" is a proper noun, \".\" is punctuation, etc.\n",
    "\n",
    "* lets see what else spacy can give us. for example, even though we just merged all of the sentences of the text, spacy can also split the text back out into sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will call the roll on May 2nd.\n",
      "May 2nd, 2022 Council briefing meeting will come to order.\n",
      "I am Andrew Lewis, Council President pro tem.\n",
      "The time is 2.01 p.m.\n",
      "Will the clerk please call the roll?\n",
      "Councilmember Wilson?\n",
      "Present.\n",
      "Councilmember Peterson? Present.\n",
      "Councilmember Sawant?\n",
      "Present.\n",
      "Councilmember Strauss?\n"
     ]
    }
   ],
   "source": [
    "# split the doc into sentences and print the first 10\n",
    "for i, sent in enumerate(doc.sents):\n",
    "    print(sent)\n",
    "\n",
    "    if i == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Great! Spacy is able to split the text back out into sentences. This is useful for many tasks such as named entity recognition, summarization, and more.\n",
    "\n",
    "* just to highlight, it also correctly ignores the \".\" (periods) in the middle of \"2.01 p.m.\" so we know that it isn't just naively splitting the text on various punctuation marks\n",
    "\n",
    "* lets try another example\n",
    "\n",
    "* part of speech tagging as we just showed can be incredibly useful but just parts of speech alone may not get you the full way. Maybe you want to track _who_ is the chair of the meeting by looking at _who_ is calling the meeting to order.\n",
    "\n",
    "* lets look at the dependency graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"81729f3d5c1646cc8787444cbb2ef8e6-0\" class=\"displacy\" width=\"1625\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PUNCT</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">I</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">am</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">Andrew</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">Lewis,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">Council</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">President</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">pro</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">X</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">tem</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">X</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-81729f3d5c1646cc8787444cbb2ef8e6-0-0\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-81729f3d5c1646cc8787444cbb2ef8e6-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-81729f3d5c1646cc8787444cbb2ef8e6-0-1\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-81729f3d5c1646cc8787444cbb2ef8e6-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,179.0 L587,167.0 603,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-81729f3d5c1646cc8787444cbb2ef8e6-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,2.0 750.0,2.0 750.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-81729f3d5c1646cc8787444cbb2ef8e6-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M750.0,179.0 L758.0,167.0 742.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-81729f3d5c1646cc8787444cbb2ef8e6-0-3\" stroke-width=\"2px\" d=\"M945,177.0 C945,89.5 1095.0,89.5 1095.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-81729f3d5c1646cc8787444cbb2ef8e6-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,179.0 L937,167.0 953,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-81729f3d5c1646cc8787444cbb2ef8e6-0-4\" stroke-width=\"2px\" d=\"M770,177.0 C770,2.0 1100.0,2.0 1100.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-81729f3d5c1646cc8787444cbb2ef8e6-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">appos</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1100.0,179.0 L1108.0,167.0 1092.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-81729f3d5c1646cc8787444cbb2ef8e6-0-5\" stroke-width=\"2px\" d=\"M1295,177.0 C1295,89.5 1445.0,89.5 1445.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-81729f3d5c1646cc8787444cbb2ef8e6-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,179.0 L1287,167.0 1303,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-81729f3d5c1646cc8787444cbb2ef8e6-0-6\" stroke-width=\"2px\" d=\"M1120,177.0 C1120,2.0 1450.0,2.0 1450.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-81729f3d5c1646cc8787444cbb2ef8e6-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">appos</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1450.0,179.0 L1458.0,167.0 1442.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.render(doc[20:30], style=\"dep\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* this gives us a much clearer view that \"andrew Lewis\" is a compound proper noun (a name) and that they are the \"Council President\" pro tem.\n",
    "\n",
    "* we can read that in the text, but by using the dependency graph we can also programmatically extract that information\n",
    "\n",
    "* lets try another example\n",
    "\n",
    "* one of the most common reasons people use spacy is for named entity recognition\n",
    "\n",
    "* named entity recognition is the task of identifying and classifying named entities in text\n",
    "\n",
    "* named entities are things like people, places, organizations, etc.\n",
    "\n",
    "* lets see what spacy can do for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "May 2nd \t\t DATE\n",
      "May 2nd, 2022 \t\t DATE\n",
      "Andrew Lewis \t\t PERSON\n",
      "Council \t\t ORG\n",
      "2.01 p.m. \t\t TIME\n"
     ]
    }
   ],
   "source": [
    "# programmatically print any named entities from the first 40 words of the meeting\n",
    "for ent in doc[:40].ents:\n",
    "    print(ent.text, \"\\t\\t\", ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I will call the roll on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    May 2nd\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ". \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    May 2nd, 2022\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " Council briefing meeting will come to order. I am \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Andrew Lewis\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Council\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " President pro tem. The time is \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2.01 p.m.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n",
       "</mark>\n",
       " Will the clerk please </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# or render them visually!\n",
    "displacy.render(doc[:40], style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* spacy is exceptional at helping with all of the lower level natural language processing tasks\n",
    "\n",
    "* and combining spacy and other open source models made available on huggingface can be a powerful combination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Idea\n",
    "\n",
    "* give a few examples of models for a certain task (maybe NER) on huggingface and ask students to compare the results between all of the models\n",
    "\n",
    "* what works well, what doesn't, etc.\n",
    "\n",
    "* similarly, ask them to combine spacy NER with a huggingface model to ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-for-pit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
