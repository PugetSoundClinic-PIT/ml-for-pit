{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Off the Shelf Machine Learning Models for Text\n",
    "\n",
    "We are going to dive directly into applying Named-Entity Recognition (NER) models.\n",
    "\n",
    "So here is what we will all do:\n",
    "In last weeks repository where we did the basic data pulling and processing:\n",
    "* Activate your conda environment that you used last week (or if you deleted it, make a new conda environment)\n",
    "* Install spacy (pip install spacy then python -m spacy download en_core_web_trf) https://spacy.io/\n",
    "* Install transformers (pip install transformers) https://huggingface.co/docs/transformers/index\n",
    "  * If you haven't used the transformers library at all all you need to know for now is that is a general system for applying thousands of custom trained and freely available models, a lot of them state-of-the-art.\n",
    "* Install flair (pip install flair) https://github.com/flairNLP/flair\n",
    "* Create a new notebook\n",
    "* Reuse the code you wrote last week to pull a months worth of meeting data.\n",
    "* Read through the documentation on how to use their NER models against portions of text:\n",
    "\n",
    "For spacy see the example code snippet section on their main page (https://spacy.io/)\n",
    "For transformers I would recommend using this model and following its \"How to use\" section: https://huggingface.co/dslim/bert-large-NER\n",
    "For flair see their example usage section: https://github.com/flairNLP/flair#example-usage\n",
    "\n",
    "Use the three NER models with each sentences text in each meeting in your month worth of data.\n",
    "Store metrics for each of the model results per sentence so that you can analyze the data in bulk later.\n",
    "\n",
    "If I was to recommend a data structure I might do something like the following (i.e. a where each row is details about a single recognized entity):\n",
    "I would also recommend storing this dataframe to a CSV for easier access later on so you dont need to reprocess everything.\n",
    "\n",
    "```\n",
    "session_id | ner_model   | sentence_index | named_entity_type | entity\n",
    "abcd1234   | spacy       | 0              | person            | eva\n",
    "abcd1234   | flair       | 0              | person            | eva\n",
    "abcd1234   | transformers| 0              | person            | eva\n",
    "abcd1234   | spacy       | 0              | organization      | University of Washington\n",
    "```\n",
    "\n",
    "Then plot your results with seaborn (pip install seaborn -- https://seaborn.pydata.org/examples/index.html) and answer these questions using each models data (i.e. answer question 1 with only spacy model results, then answer question 1 with only transformer model results, etc. -- there are fancy methods of comparison plotting but we can get into that later):\n",
    "\n",
    "1. What types of entities are recognized over all the meetings? I.e. How many are people? How many are organizations? etc.\n",
    "2. What meetings have more or less entities recognized overall? We want to see the distribution of entities mentioned over different meetings. I.e. Meeting abcd1234 had 204 recognized entities, meeting efgh5678 had 559 recognized entities, etc.\n",
    "3. Make a third plot that is entirely up to you. Come up with a question and try to answer it via a plot.\n",
    "\n",
    "All of you use three months of data from Seattle, Oakland, and Louisville\n",
    "start date of \"2022-09-01\"\n",
    "end date of \"2022-12-01\"\n",
    "\n",
    "Only use spacy for labeling / prediction\n",
    "\n",
    "Plot the results!\n",
    "Normalize the x-axis / the \"sentence-index\" to be \"percent-progress-in-meeting\" or similar for now -- i like the idea of segmenting the meeting from \n",
    "\n",
    "Average across all meetings\n",
    "\n",
    "Break out the results by council (Seattle, Oakland, and Louisville) and by entity type (People, Organizations, NORGS) and by other factors?\n",
    "\n",
    "What are the top entities mentioned on average across all meetings?\n",
    "\n",
    "**Can you filter some out (\"Seattle City Council\" should probably be filtered out for example)**\n",
    "\n",
    "Work together on processing the data and getting it into a format that you are comfortable plotting and then each of you try plotting it. Variation is important -- we can see how different people interpret visualizations once you are all done\n",
    "The timeline plot can be useful but are there other ways of plotting this data that tease out more statistical values we can use?\n",
    "If you have time and are happy with what you have done on the above stuff -- it might also be interesting to pull out a sample of the labelled data and give examples for how we might answer the next couple of questions:\n",
    "How are they referenced?\n",
    "The sentiment of the sentence\n",
    "Do sentences with PERSON entities have on average higher or lower sentiment than sentences with ORG entities for example?\n",
    "Plot this and then pull out examples from the text\n",
    "Are there references to the same interest group in different councils?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-for-pit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "58cd6e08b9735120d5b4eff7d74c8f325757ca8d93d795a23730f4ff64520fa2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
